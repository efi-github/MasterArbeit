{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:40.812169Z",
     "start_time": "2024-06-02T06:47:38.612843Z"
    }
   },
   "source": [
    "from _0_mamba_vs_neo.models.MambaForSequenceClassification import MambaForSequenceClassification\n",
    "import _0_mamba_vs_neo.datasets.ecthr.utils_ecthr as utils_ecthr"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.350111Z",
     "start_time": "2024-06-02T06:47:40.813364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, hamming_loss\n",
    "import os"
   ],
   "id": "9fb2a38aeb33a5e2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.355275Z",
     "start_time": "2024-06-02T06:47:41.350960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "\n",
    "Train for 6 epochs with 24000 tokens without silver data, as to trying to improve our current results.\n",
    "\"\"\""
   ],
   "id": "ac5ed7f616dc4907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription:\\n\\nTrain for 6 epochs with 24000 tokens without silver data, as to trying to improve our current results.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.365461Z",
     "start_time": "2024-06-02T06:47:41.356021Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"WANDB_PROJECT\"] = \"mamba_vs_neo_ecthr\"",
   "id": "e432f5a75cfa04ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.373219Z",
     "start_time": "2024-06-02T06:47:41.366770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CONFIGS:\n",
    "\"\"\""
   ],
   "id": "7302d5b13c10aea0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCONFIGS:\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.380713Z",
     "start_time": "2024-06-02T06:47:41.373956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    general:\n",
    "        - RUN_NAME: str\n",
    "            name of the run\n",
    "        - OUTPUT_DIR: str\n",
    "            directory to save the model and logs\n",
    "        - SEED: int\n",
    "            random seed to use\n",
    "        - REPORT_TO: str\n",
    "\"\"\"\n",
    "RUN_NAME = \"mamba_run_24000_tokens_6_epochs_no_silver\"\n",
    "OUTPUT_DIR = f\"_0_mamba_vs_neo/models/mamba/{RUN_NAME}\"\n",
    "SEED = 42\n",
    "REPORT_TO = \"wandb\""
   ],
   "id": "89a6f0a4fc3c0f0d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.389123Z",
     "start_time": "2024-06-02T06:47:41.381512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    dataset:\n",
    "        - ALLEGATIONS: bool\n",
    "            True: use allegation data for the cases, so what laws did the cases allegedly violate\n",
    "            False: use court decisions, so what laws did the court decide the cases violated\n",
    "        - SILVER: bool\n",
    "            True: only use facts which were deemed relevant by the court\n",
    "            False: use all facts\n",
    "        - MULTI_LABEL: bool\n",
    "            True: use multi-label classification (which law was (allegedly) violated)\n",
    "            False: use binary classification (was there a law (allegedly) violated)\n",
    "        - FREQUENCY_THRESHOLD: int\n",
    "            minimum number of cases a law must be (allegedly) violated in to be considered\n",
    "        - NUM_LABELS: int\n",
    "            number of labels in the dataset (ecthr: 41)\n",
    "        - MAX_LENGTH: int\n",
    "            maximum number of tokens in a sequence     \n",
    "\"\"\"\n",
    "ALLEGATIONS = True\n",
    "SILVER = False\n",
    "MULTI_LABEL = True\n",
    "FREQUENCY_THRESHOLD = 0\n",
    "NUM_LABELS = 41\n",
    "\n",
    "MAX_LENGTH = 24000"
   ],
   "id": "6befe586279fd39c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.397771Z",
     "start_time": "2024-06-02T06:47:41.389829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    training:\n",
    "        - EPOCHS: int\n",
    "            number of times to iterate over the dataset\n",
    "        - LEARNING_RATE: float\n",
    "            rate at which the model learns\n",
    "        - BATCH_SIZE: int\n",
    "            number of sequences in a batch\n",
    "        - GRADIENT_ACCUMULATION_STEPS: int\n",
    "            number of batches to accumulate gradients over\n",
    "        - USE_LENGTH_GROUPING: bool\n",
    "            True: group sequences of similar length together to minimize padding\n",
    "            False: do not group sequences by length\n",
    "        - WARMUP_RATIO: float\n",
    "            ratio of training steps to warmup steps\n",
    "        - MAX_GRAD_NORM: float\n",
    "            maximum gradient norm to clip to\n",
    "        - WEIGHT_DECAY: float\n",
    "            weight decay to apply to the model\n",
    "\"\"\"\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = 16\n",
    "print(\"true batch size:\", BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)\n",
    "\n",
    "WARMUP_RATIO = 0.1\n",
    "MAX_GRAD_NORM = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "\n",
    "USE_LENGTH_GROUPING = True"
   ],
   "id": "893de6da13f235d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true batch size: 16\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.405992Z",
     "start_time": "2024-06-02T06:47:41.398708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    evaluation:\n",
    "        - EVAL_STEPS: int\n",
    "            number of steps between evaluations\n",
    "        - BATCH_SIZE_EVAL: int\n",
    "            number of sequences in a batch for evaluation\n",
    "        - LOGGING_STEPS: int\n",
    "            number of steps between logging\n",
    "        - EVAL_ACCUMULATION_STEPS: int\n",
    "            number eval batches to calculate before copying to the cpu, if the eval requires a lot of memory this is helpful\n",
    "\"\"\"\n",
    "EVAL_STEPS = 200\n",
    "BATCH_SIZE_EVAL = BATCH_SIZE\n",
    "LOGGING_STEPS = 100\n",
    "EVAL_ACCUMULATION_STEPS = 20"
   ],
   "id": "baba926e7f85c13b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.413355Z",
     "start_time": "2024-06-02T06:47:41.406713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    model:\n",
    "        - MODEL_NAME: str\n",
    "            name of the model to use\n",
    "        - LORA_TASK_TYPE:\n",
    "        - LORA_R: int\n",
    "           r is the rank of the approximation\n",
    "        - LORA_TARGET_MODULES: list\n",
    "            list of modules to target with LoRA\n",
    "\"\"\"\n",
    "MODEL_NAME = \"state-spaces/mamba-1.4b-hf\"\n",
    "LORA_TASK_TYPE = TaskType.SEQ_CLS\n",
    "LORA_R = 8\n",
    "LORA_TARGET_MODULES = [\"x_proj\", \"embeddings\", \"in_proj\", \"out_proj\"]"
   ],
   "id": "a1937d47960adb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.421703Z",
     "start_time": "2024-06-02T06:47:41.414198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    \n",
    "    precision_macro, recall_macto, f1_macro, _ = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, predictions, average='micro', zero_division=0)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'strict_accuracy': accuracy,\n",
    "        'hamming_accuracy': 1 - hamming_loss(labels, predictions),\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_macro': recall_macto,\n",
    "        'recall_micro': recall_micro\n",
    "    }"
   ],
   "id": "ca5335c6d3836d38",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:41.429996Z",
     "start_time": "2024-06-02T06:47:41.422631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleBCELossTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = self.loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "id": "a5429b5b3fa7540c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:42.899533Z",
     "start_time": "2024-06-02T06:47:41.430813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MambaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\")"
   ],
   "id": "6267f525c2c7421f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "811e546af19c493086a8036fa02e9246"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MambaForSequenceClassification were not initialized from the model checkpoint at state-spaces/mamba-1.4b-hf and are newly initialized: ['backbone.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:42.903736Z",
     "start_time": "2024-06-02T06:47:42.901668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "58d4063fa0ee2176",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:42.911656Z",
     "start_time": "2024-06-02T06:47:42.904467Z"
    }
   },
   "cell_type": "code",
   "source": "collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = True)",
   "id": "8b1592b4547f7fc9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:46.050225Z",
     "start_time": "2024-06-02T06:47:42.912457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ecthr_dataset = utils_ecthr.load_ecthr_dataset(allegations=ALLEGATIONS, silver=SILVER, is_multi_label=MULTI_LABEL, frequency_threshold=FREQUENCY_THRESHOLD)\n",
    "ecthr_dataset = utils_ecthr.tokenize_dataset(ecthr_dataset, tokenizer, max_length=MAX_LENGTH)\n",
    "ecthr_dataset = ecthr_dataset.remove_columns(\"facts\")"
   ],
   "id": "cc2df7d0da5e4328",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:46.052978Z",
     "start_time": "2024-06-02T06:47:46.050942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = ecthr_dataset[\"train\"]\n",
    "val = ecthr_dataset[\"validation\"]\n",
    "test = ecthr_dataset[\"test\"]"
   ],
   "id": "43a3d065e7e80583",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:46.061596Z",
     "start_time": "2024-06-02T06:47:46.053704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config =  LoraConfig(\n",
    "        r=LORA_R,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        task_type=LORA_TASK_TYPE,\n",
    "        bias=\"none\"\n",
    ")"
   ],
   "id": "79702f6a279249d1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:46.194378Z",
     "start_time": "2024-06-02T06:47:46.062520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "56fe4e927b2759d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,428,352 || all params: 1,380,690,752 || trainable%: 0.6104\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:46.960256Z",
     "start_time": "2024-06-02T06:47:46.195149Z"
    }
   },
   "cell_type": "code",
   "source": "model.to(\"cuda\")",
   "id": "bccf92a23ac3a46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MambaForSequenceClassification(\n",
       "      (embeddings): lora.Embedding(\n",
       "        (base_layer): Embedding(50280, 2048)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict()\n",
       "        (lora_B): ModuleDict()\n",
       "        (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 8x50280 (cuda:0)])\n",
       "        (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (cuda:0)])\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-47): 48 x MambaBlock(\n",
       "          (norm): MambaRMSNorm()\n",
       "          (mixer): MambaMixer(\n",
       "            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)\n",
       "            (act): SiLU()\n",
       "            (in_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (x_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=160, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=160, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (dt_proj): Linear(in_features=128, out_features=4096, bias=True)\n",
       "            (out_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): MambaRMSNorm()\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:46.967404Z",
     "start_time": "2024-06-02T06:47:46.961098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ],
   "id": "cbc50cb119f59b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.embeddings.lora_embedding_A.default\n",
      "base_model.model.embeddings.lora_embedding_B.default\n",
      "base_model.model.layers.0.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.classifier.modules_to_save.default.weight\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:46.987512Z",
     "start_time": "2024-06-02T06:47:46.968282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= OUTPUT_DIR,\n",
    "    run_name= RUN_NAME,\n",
    "    learning_rate= LEARNING_RATE,\n",
    "    lr_scheduler_type= \"constant\",\n",
    "    warmup_ratio= WARMUP_RATIO,\n",
    "    max_grad_norm= MAX_GRAD_NORM,\n",
    "    per_device_train_batch_size= BATCH_SIZE,\n",
    "    per_device_eval_batch_size= BATCH_SIZE_EVAL,\n",
    "    gradient_accumulation_steps= GRADIENT_ACCUMULATION_STEPS,#\n",
    "    group_by_length= USE_LENGTH_GROUPING,\n",
    "    num_train_epochs= EPOCHS,\n",
    "    weight_decay= WEIGHT_DECAY,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps= EVAL_STEPS,\n",
    "    eval_accumulation_steps = EVAL_ACCUMULATION_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps= EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to= REPORT_TO,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps= LOGGING_STEPS,\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ],
   "id": "4aea53a3acaa584f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T06:47:47.145428Z",
     "start_time": "2024-06-02T06:47:46.988336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = SimpleBCELossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "33280cfe33e287e1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:04:30.269289Z",
     "start_time": "2024-06-02T06:47:47.146169Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train(resume_from_checkpoint=True)",
   "id": "db97522ffc2fbbd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33melisabeth-fittschen\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/efi/Desktop/MasterArbeit/_0_mamba_vs_neo/src/mamba/wandb/run-20240602_084757-533dfd45</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/533dfd45' target=\"_blank\">mamba_run_24000_tokens_6_epochs_no_silver</a></strong> to <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/533dfd45' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/533dfd45</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3372' max='3372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3372/3372 17:16:25, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Strict Accuracy</th>\n",
       "      <th>Hamming Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.079067</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.973122</td>\n",
       "      <td>0.107863</td>\n",
       "      <td>0.603026</td>\n",
       "      <td>0.141859</td>\n",
       "      <td>0.743339</td>\n",
       "      <td>0.097210</td>\n",
       "      <td>0.507273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.071631</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.975732</td>\n",
       "      <td>0.123269</td>\n",
       "      <td>0.634326</td>\n",
       "      <td>0.150037</td>\n",
       "      <td>0.805789</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.523030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.067899</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.976805</td>\n",
       "      <td>0.136091</td>\n",
       "      <td>0.665494</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.792959</td>\n",
       "      <td>0.123839</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.065477</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.978390</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.692147</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.811075</td>\n",
       "      <td>0.145344</td>\n",
       "      <td>0.603636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.062717</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>0.979220</td>\n",
       "      <td>0.160020</td>\n",
       "      <td>0.703136</td>\n",
       "      <td>0.219521</td>\n",
       "      <td>0.827049</td>\n",
       "      <td>0.142279</td>\n",
       "      <td>0.611515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.061104</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>0.979976</td>\n",
       "      <td>0.186992</td>\n",
       "      <td>0.712233</td>\n",
       "      <td>0.211954</td>\n",
       "      <td>0.844555</td>\n",
       "      <td>0.170635</td>\n",
       "      <td>0.615758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.060221</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.980512</td>\n",
       "      <td>0.187606</td>\n",
       "      <td>0.724007</td>\n",
       "      <td>0.209797</td>\n",
       "      <td>0.841767</td>\n",
       "      <td>0.173293</td>\n",
       "      <td>0.635152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.059561</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>0.980610</td>\n",
       "      <td>0.197476</td>\n",
       "      <td>0.729867</td>\n",
       "      <td>0.234647</td>\n",
       "      <td>0.830626</td>\n",
       "      <td>0.180219</td>\n",
       "      <td>0.650909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.058996</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>0.980585</td>\n",
       "      <td>0.190786</td>\n",
       "      <td>0.727210</td>\n",
       "      <td>0.235547</td>\n",
       "      <td>0.836751</td>\n",
       "      <td>0.171892</td>\n",
       "      <td>0.643030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.059575</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.980610</td>\n",
       "      <td>0.204646</td>\n",
       "      <td>0.731146</td>\n",
       "      <td>0.235661</td>\n",
       "      <td>0.827085</td>\n",
       "      <td>0.187172</td>\n",
       "      <td>0.655152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.057730</td>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.981073</td>\n",
       "      <td>0.205912</td>\n",
       "      <td>0.730929</td>\n",
       "      <td>0.237020</td>\n",
       "      <td>0.854133</td>\n",
       "      <td>0.189168</td>\n",
       "      <td>0.638788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>0.981488</td>\n",
       "      <td>0.201468</td>\n",
       "      <td>0.740335</td>\n",
       "      <td>0.240236</td>\n",
       "      <td>0.849961</td>\n",
       "      <td>0.183780</td>\n",
       "      <td>0.655758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.057966</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>0.980756</td>\n",
       "      <td>0.203050</td>\n",
       "      <td>0.728586</td>\n",
       "      <td>0.231358</td>\n",
       "      <td>0.842482</td>\n",
       "      <td>0.185392</td>\n",
       "      <td>0.641818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3372, training_loss=0.04639049222602256, metrics={'train_runtime': 62193.7453, 'train_samples_per_second': 0.868, 'train_steps_per_second': 0.054, 'total_flos': 8.460914581745948e+17, 'train_loss': 0.04639049222602256, 'epoch': 5.995555555555556})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:04:30.273084Z",
     "start_time": "2024-06-03T00:04:30.270205Z"
    }
   },
   "cell_type": "code",
   "source": "print(trainer)",
   "id": "b24da0c5397d09c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SimpleBCELossTrainer object at 0x7f405c1a3ac0>\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:12:15.238096Z",
     "start_time": "2024-06-03T00:04:30.273943Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(test)",
   "id": "5b4c111841d19ceb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05875522270798683,\n",
       " 'eval_strict_accuracy': 0.503,\n",
       " 'eval_hamming_accuracy': 0.9813170731707317,\n",
       " 'eval_f1_macro': 0.19638829828582866,\n",
       " 'eval_f1_micro': 0.7401628222523745,\n",
       " 'eval_precision_macro': 0.26463790068564746,\n",
       " 'eval_precision_micro': 0.86793953858393,\n",
       " 'eval_recall_macro': 0.17357790370550572,\n",
       " 'eval_recall_micro': 0.6451803666469544,\n",
       " 'eval_runtime': 464.9518,\n",
       " 'eval_samples_per_second': 2.151,\n",
       " 'eval_steps_per_second': 2.151,\n",
       " 'epoch': 5.995555555555556}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:20:00.169075Z",
     "start_time": "2024-06-03T00:12:15.239119Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = trainer.predict(test)",
   "id": "4d6cbf2282b280af",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:20:00.173945Z",
     "start_time": "2024-06-03T00:20:00.170066Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "8ee9ece7f37c6ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ -5.176667 ,  -3.4321737,  -7.507284 , ...,  -9.13706  ,\n",
       "         -9.13706  ,  -9.13706  ],\n",
       "       [ -3.9836233,  -3.4444451,  -6.4422345, ...,  -9.466854 ,\n",
       "         -9.466854 ,  -9.466854 ],\n",
       "       [ -5.2913375,  -5.354499 ,  -7.378887 , ..., -10.212474 ,\n",
       "        -10.212474 , -10.212474 ],\n",
       "       ...,\n",
       "       [ -5.2673464,  -2.318149 ,  -6.707821 , ...,  -9.407799 ,\n",
       "         -9.407799 ,  -9.407799 ],\n",
       "       [ -4.0101576,   3.081163 ,  -7.1755342, ...,  -9.695277 ,\n",
       "         -9.695277 ,  -9.695277 ],\n",
       "       [ -5.0343504,   1.9087962,  -6.6021767, ...,  -9.3357935,\n",
       "         -9.3357935,  -9.3357935]], dtype=float32), label_ids=array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), metrics={'test_loss': 0.05875522270798683, 'test_strict_accuracy': 0.503, 'test_hamming_accuracy': 0.9813170731707317, 'test_f1_macro': 0.19638829828582866, 'test_f1_micro': 0.7401628222523745, 'test_precision_macro': 0.26463790068564746, 'test_precision_micro': 0.86793953858393, 'test_recall_macro': 0.17357790370550572, 'test_recall_micro': 0.6451803666469544, 'test_runtime': 464.9255, 'test_samples_per_second': 2.151, 'test_steps_per_second': 2.151})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:20:00.184687Z",
     "start_time": "2024-06-03T00:20:00.174725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calulate_metrics_index(predictions, index):\n",
    "    logits = predictions.predictions\n",
    "    labels = predictions.label_ids\n",
    "    \n",
    "    logits = logits[:, index]\n",
    "    labels = labels[:, index]\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    count_correct = np.sum(labels)\n",
    "    count_predicted = np.sum(predictions)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'count_cases': count_correct,\n",
    "        'count_predicted': count_predicted\n",
    "    }\n"
   ],
   "id": "555e12e100ce0f50",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:20:00.197440Z",
     "start_time": "2024-06-03T00:20:00.185512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = utils_ecthr.ARTICLES_ID\n",
    "ids = {v: k for k, v in ids.items()}\n",
    "desc = utils_ecthr.ARTICLES_DESC\n"
   ],
   "id": "9e98169c432a3e5",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:20:00.273091Z",
     "start_time": "2024-06-03T00:20:00.198421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(0, 41):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Label {i}\")\n",
    "    print(ids[i])\n",
    "    print(desc[ids[i]])\n",
    "    print(calulate_metrics_index(predictions, i))"
   ],
   "id": "21914b194e6829cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Label 0\n",
      "2\n",
      "Right to life\n",
      "{'f1': 0.835820895522388, 'precision': 0.9655172413793104, 'recall': 0.7368421052631579, 'count_cases': 76, 'count_predicted': 58}\n",
      "--------------------------------------------------\n",
      "Label 1\n",
      "3\n",
      "Prohibition of torture\n",
      "{'f1': 0.869198312236287, 'precision': 0.8583333333333333, 'recall': 0.8803418803418803, 'count_cases': 234, 'count_predicted': 240}\n",
      "--------------------------------------------------\n",
      "Label 2\n",
      "4\n",
      "Prohibition of slavery and forced labour\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 3\n",
      "5\n",
      "Right to liberty and security\n",
      "{'f1': 0.8287292817679558, 'precision': 0.9036144578313253, 'recall': 0.7653061224489796, 'count_cases': 196, 'count_predicted': 166}\n",
      "--------------------------------------------------\n",
      "Label 4\n",
      "6\n",
      "Right to a fair trial\n",
      "{'f1': 0.821522309711286, 'precision': 0.8505434782608695, 'recall': 0.7944162436548223, 'count_cases': 394, 'count_predicted': 368}\n",
      "--------------------------------------------------\n",
      "Label 5\n",
      "7\n",
      "No punishment without law\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 10, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 6\n",
      "8\n",
      "Right to respect for private and family life\n",
      "{'f1': 0.7142857142857143, 'precision': 0.9166666666666666, 'recall': 0.5851063829787234, 'count_cases': 188, 'count_predicted': 120}\n",
      "--------------------------------------------------\n",
      "Label 7\n",
      "9\n",
      "Freedom of thought, conscience and religion\n",
      "{'f1': 0.42857142857142855, 'precision': 1.0, 'recall': 0.2727272727272727, 'count_cases': 11, 'count_predicted': 3}\n",
      "--------------------------------------------------\n",
      "Label 8\n",
      "10\n",
      "Freedom of expression\n",
      "{'f1': 0.8, 'precision': 0.9047619047619048, 'recall': 0.7169811320754716, 'count_cases': 106, 'count_predicted': 84}\n",
      "--------------------------------------------------\n",
      "Label 9\n",
      "11\n",
      "Freedom of assembly and association\n",
      "{'f1': 0.6756756756756757, 'precision': 0.8064516129032258, 'recall': 0.5813953488372093, 'count_cases': 43, 'count_predicted': 31}\n",
      "--------------------------------------------------\n",
      "Label 10\n",
      "12\n",
      "Right to marry\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 4, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 11\n",
      "13\n",
      "Right to an effective remedy\n",
      "{'f1': 0.2097902097902098, 'precision': 0.75, 'recall': 0.12195121951219512, 'count_cases': 123, 'count_predicted': 20}\n",
      "--------------------------------------------------\n",
      "Label 12\n",
      "14\n",
      "Prohibition of discrimination\n",
      "{'f1': 0.24390243902439024, 'precision': 0.5555555555555556, 'recall': 0.15625, 'count_cases': 32, 'count_predicted': 9}\n",
      "--------------------------------------------------\n",
      "Label 13\n",
      "15\n",
      "Derogation in time of emergency\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 14\n",
      "16\n",
      "Restrictions on political activity of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 15\n",
      "17\n",
      "Prohibition of abuse of rights\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 16\n",
      "18\n",
      "Limitation on use of restrictions on rights\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 14, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 17\n",
      "34\n",
      "Individual applications\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 48, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 18\n",
      "38\n",
      "Examination of the case\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 19\n",
      "39\n",
      "Friendly settlements\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 20\n",
      "46\n",
      "Binding force and execution of judgments\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 21, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 21\n",
      "P1-1\n",
      "Protection of property\n",
      "{'f1': 0.8387096774193549, 'precision': 0.8387096774193549, 'recall': 0.8387096774193549, 'count_cases': 155, 'count_predicted': 155}\n",
      "--------------------------------------------------\n",
      "Label 22\n",
      "P1-2\n",
      "Right to education\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 5, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 23\n",
      "P1-3\n",
      "Right to free elections\n",
      "{'f1': 0.5, 'precision': 0.5, 'recall': 0.5, 'count_cases': 2, 'count_predicted': 2}\n",
      "--------------------------------------------------\n",
      "Label 24\n",
      "P3-1\n",
      "Right to free elections\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 25\n",
      "P4-1\n",
      "Prohibition of imprisonment for debt\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 26\n",
      "P4-2\n",
      "Freedom of movement\n",
      "{'f1': 0.2857142857142857, 'precision': 1.0, 'recall': 0.16666666666666666, 'count_cases': 6, 'count_predicted': 1}\n",
      "--------------------------------------------------\n",
      "Label 27\n",
      "P4-3\n",
      "Prohibition of expulsion of nationals\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 28\n",
      "P4-4\n",
      "Prohibition of collective expulsion of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 29\n",
      "P6-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 30\n",
      "P6-2\n",
      "Death penalty in time of war\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 31\n",
      "P6-3\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 32\n",
      "P7-1\n",
      "Procedural safeguards relating to expulsion of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 33\n",
      "P7-2\n",
      "Right of appeal in criminal matters\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 4, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 34\n",
      "P7-3\n",
      "Compensation for wrongful conviction\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 35\n",
      "P7-4\n",
      "Right not to be tried or punished twice\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 5, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 36\n",
      "P7-5\n",
      "Equality between spouses\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 37\n",
      "P12-1\n",
      "General prohibition of discrimination\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 38\n",
      "P13-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 39\n",
      "P13-2\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 40\n",
      "P13-3\n",
      "Prohibition of reservations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:20:00.279146Z",
     "start_time": "2024-06-03T00:20:00.274010Z"
    }
   },
   "cell_type": "code",
   "source": "calulate_metrics_index(predictions, 2)",
   "id": "98b38f03c11137fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'count_cases': 3,\n",
       " 'count_predicted': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
