{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:58.189699Z",
     "start_time": "2024-05-27T21:28:55.089096Z"
    }
   },
   "source": [
    "from _0_mamba_vs_neo.models.MambaForSequenceClassification import MambaForSequenceClassification\n",
    "import _0_mamba_vs_neo.datasets.ecthr.utils_ecthr as utils_ecthr"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.028104Z",
     "start_time": "2024-05-27T21:28:58.190771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, hamming_loss\n",
    "import os"
   ],
   "id": "9fb2a38aeb33a5e2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.034950Z",
     "start_time": "2024-05-27T21:28:59.028871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "\n",
    "Train for 6 epochs with 512 tokens without silver data, as to recreate the environment of the original ecthr paper.\n",
    "\"\"\""
   ],
   "id": "ac5ed7f616dc4907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription:\\n\\nTrain for 6 epochs with 512 tokens without silver data, as to recreate the environment of the original ecthr paper.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.042008Z",
     "start_time": "2024-05-27T21:28:59.035947Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"WANDB_PROJECT\"] = \"mamba_vs_neo_ecthr\"",
   "id": "e432f5a75cfa04ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.050697Z",
     "start_time": "2024-05-27T21:28:59.044138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CONFIGS:\n",
    "\"\"\""
   ],
   "id": "7302d5b13c10aea0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCONFIGS:\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.058823Z",
     "start_time": "2024-05-27T21:28:59.051798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    general:\n",
    "        - RUN_NAME: str\n",
    "            name of the run\n",
    "        - OUTPUT_DIR: str\n",
    "            directory to save the model and logs\n",
    "        - SEED: int\n",
    "            random seed to use\n",
    "        - REPORT_TO: str\n",
    "\"\"\"\n",
    "RUN_NAME = \"mamba_run_512_tokens_6_epochs_no_silver\"\n",
    "OUTPUT_DIR = f\"_0_mamba_vs_neo/models/mamba/{RUN_NAME}\"\n",
    "SEED = 42\n",
    "REPORT_TO = \"wandb\""
   ],
   "id": "89a6f0a4fc3c0f0d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.068113Z",
     "start_time": "2024-05-27T21:28:59.059921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    dataset:\n",
    "        - ALLEGATIONS: bool\n",
    "            True: use allegation data for the cases, so what laws did the cases allegedly violate\n",
    "            False: use court decisions, so what laws did the court decide the cases violated\n",
    "        - SILVER: bool\n",
    "            True: only use facts which were deemed relevant by the court\n",
    "            False: use all facts\n",
    "        - MULTI_LABEL: bool\n",
    "            True: use multi-label classification (which law was (allegedly) violated)\n",
    "            False: use binary classification (was there a law (allegedly) violated)\n",
    "        - FREQUENCY_THRESHOLD: int\n",
    "            minimum number of cases a law must be (allegedly) violated in to be considered\n",
    "        - NUM_LABELS: int\n",
    "            number of labels in the dataset (ecthr: 41)\n",
    "        - MAX_LENGTH: int\n",
    "            maximum number of tokens in a sequence     \n",
    "\"\"\"\n",
    "ALLEGATIONS = True\n",
    "SILVER = False\n",
    "MULTI_LABEL = True\n",
    "FREQUENCY_THRESHOLD = 0\n",
    "NUM_LABELS = 41\n",
    "\n",
    "MAX_LENGTH = 512"
   ],
   "id": "6befe586279fd39c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.076690Z",
     "start_time": "2024-05-27T21:28:59.069228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    training:\n",
    "        - EPOCHS: int\n",
    "            number of times to iterate over the dataset\n",
    "        - LEARNING_RATE: float\n",
    "            rate at which the model learns\n",
    "        - BATCH_SIZE: int\n",
    "            number of sequences in a batch\n",
    "        - GRADIENT_ACCUMULATION_STEPS: int\n",
    "            number of batches to accumulate gradients over\n",
    "        - USE_LENGTH_GROUPING: bool\n",
    "            True: group sequences of similar length together to minimize padding\n",
    "            False: do not group sequences by length\n",
    "        - WARMUP_RATIO: float\n",
    "            ratio of training steps to warmup steps\n",
    "        - MAX_GRAD_NORM: float\n",
    "            maximum gradient norm to clip to\n",
    "        - WEIGHT_DECAY: float\n",
    "            weight decay to apply to the model\n",
    "\"\"\"\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 8\n",
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "print(\"true batch size:\", BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)\n",
    "\n",
    "WARMUP_RATIO = 0.1\n",
    "MAX_GRAD_NORM = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "\n",
    "USE_LENGTH_GROUPING = True"
   ],
   "id": "893de6da13f235d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true batch size: 16\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.085788Z",
     "start_time": "2024-05-27T21:28:59.077945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    evaluation:\n",
    "        - EVAL_STEPS: int\n",
    "            number of steps between evaluations\n",
    "        - BATCH_SIZE_EVAL: int\n",
    "            number of sequences in a batch for evaluation\n",
    "        - LOGGING_STEPS: int\n",
    "            number of steps between logging\n",
    "        - EVAL_ACCUMULATION_STEPS: int\n",
    "            number eval batches to calculate before copying to the cpu, if the eval requires a lot of memory this is helpful\n",
    "\"\"\"\n",
    "EVAL_STEPS = 200\n",
    "BATCH_SIZE_EVAL = BATCH_SIZE\n",
    "LOGGING_STEPS = 100\n",
    "EVAL_ACCUMULATION_STEPS = 20"
   ],
   "id": "baba926e7f85c13b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.093786Z",
     "start_time": "2024-05-27T21:28:59.086577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    model:\n",
    "        - MODEL_NAME: str\n",
    "            name of the model to use\n",
    "        - LORA_TASK_TYPE:\n",
    "        - LORA_R: int\n",
    "           r is the rank of the approximation\n",
    "        - LORA_TARGET_MODULES: list\n",
    "            list of modules to target with LoRA\n",
    "\"\"\"\n",
    "MODEL_NAME = \"state-spaces/mamba-1.4b-hf\"\n",
    "LORA_TASK_TYPE = TaskType.SEQ_CLS\n",
    "LORA_R = 8\n",
    "LORA_TARGET_MODULES = [\"x_proj\", \"embeddings\", \"in_proj\", \"out_proj\"]"
   ],
   "id": "a1937d47960adb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.101755Z",
     "start_time": "2024-05-27T21:28:59.094680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    \n",
    "    precision_macro, recall_macto, f1_macro, _ = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, predictions, average='micro', zero_division=0)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'strict_accuracy': accuracy,\n",
    "        'hamming_accuracy': 1 - hamming_loss(labels, predictions),\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_macro': recall_macto,\n",
    "        'recall_micro': recall_micro\n",
    "    }"
   ],
   "id": "ca5335c6d3836d38",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:28:59.110733Z",
     "start_time": "2024-05-27T21:28:59.102816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleBCELossTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = self.loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "id": "a5429b5b3fa7540c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:03.148314Z",
     "start_time": "2024-05-27T21:28:59.111896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MambaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\")"
   ],
   "id": "6267f525c2c7421f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9760fcf1691f4bd5b7144e8c3b6612d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MambaForSequenceClassification were not initialized from the model checkpoint at state-spaces/mamba-1.4b-hf and are newly initialized: ['backbone.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:03.153064Z",
     "start_time": "2024-05-27T21:29:03.150589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "58d4063fa0ee2176",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:03.161287Z",
     "start_time": "2024-05-27T21:29:03.153895Z"
    }
   },
   "cell_type": "code",
   "source": "collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = True)",
   "id": "8b1592b4547f7fc9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:06.954114Z",
     "start_time": "2024-05-27T21:29:03.162163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ecthr_dataset = utils_ecthr.load_ecthr_dataset(allegations=ALLEGATIONS, silver=SILVER, is_multi_label=MULTI_LABEL, frequency_threshold=FREQUENCY_THRESHOLD)\n",
    "ecthr_dataset = utils_ecthr.tokenize_dataset(ecthr_dataset, tokenizer, max_length=MAX_LENGTH)\n",
    "ecthr_dataset = ecthr_dataset.remove_columns(\"facts\")"
   ],
   "id": "cc2df7d0da5e4328",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bdbe5533e6d4091a7cd803581cfde78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:06.957123Z",
     "start_time": "2024-05-27T21:29:06.954909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = ecthr_dataset[\"train\"]\n",
    "val = ecthr_dataset[\"validation\"]\n",
    "test = ecthr_dataset[\"test\"]"
   ],
   "id": "43a3d065e7e80583",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:06.967048Z",
     "start_time": "2024-05-27T21:29:06.957920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config =  LoraConfig(\n",
    "        r=LORA_R,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        task_type=LORA_TASK_TYPE,\n",
    "        bias=\"none\"\n",
    ")"
   ],
   "id": "79702f6a279249d1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:07.099611Z",
     "start_time": "2024-05-27T21:29:06.967796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "56fe4e927b2759d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,428,352 || all params: 1,380,690,752 || trainable%: 0.6104\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:07.946996Z",
     "start_time": "2024-05-27T21:29:07.100452Z"
    }
   },
   "cell_type": "code",
   "source": "model.to(\"cuda\")",
   "id": "bccf92a23ac3a46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MambaForSequenceClassification(\n",
       "      (embeddings): lora.Embedding(\n",
       "        (base_layer): Embedding(50280, 2048)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict()\n",
       "        (lora_B): ModuleDict()\n",
       "        (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 8x50280 (cuda:0)])\n",
       "        (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (cuda:0)])\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-47): 48 x MambaBlock(\n",
       "          (norm): MambaRMSNorm()\n",
       "          (mixer): MambaMixer(\n",
       "            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)\n",
       "            (act): SiLU()\n",
       "            (in_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (x_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=160, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=160, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (dt_proj): Linear(in_features=128, out_features=4096, bias=True)\n",
       "            (out_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): MambaRMSNorm()\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:07.954343Z",
     "start_time": "2024-05-27T21:29:07.947959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ],
   "id": "cbc50cb119f59b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.embeddings.lora_embedding_A.default\n",
      "base_model.model.embeddings.lora_embedding_B.default\n",
      "base_model.model.layers.0.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.classifier.modules_to_save.default.weight\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:07.992685Z",
     "start_time": "2024-05-27T21:29:07.955255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= OUTPUT_DIR,\n",
    "    run_name= RUN_NAME,\n",
    "    learning_rate= LEARNING_RATE,\n",
    "    lr_scheduler_type= \"constant\",\n",
    "    warmup_ratio= WARMUP_RATIO,\n",
    "    max_grad_norm= MAX_GRAD_NORM,\n",
    "    per_device_train_batch_size= BATCH_SIZE,\n",
    "    per_device_eval_batch_size= BATCH_SIZE_EVAL,\n",
    "    gradient_accumulation_steps= GRADIENT_ACCUMULATION_STEPS,#\n",
    "    group_by_length= USE_LENGTH_GROUPING,\n",
    "    num_train_epochs= EPOCHS,\n",
    "    weight_decay= WEIGHT_DECAY,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps= EVAL_STEPS,\n",
    "    eval_accumulation_steps = EVAL_ACCUMULATION_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps= EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to= REPORT_TO,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps= LOGGING_STEPS,\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ],
   "id": "4aea53a3acaa584f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T21:29:08.171786Z",
     "start_time": "2024-05-27T21:29:07.993609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = SimpleBCELossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "33280cfe33e287e1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:54:45.128401Z",
     "start_time": "2024-05-27T21:29:08.172664Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "db97522ffc2fbbd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33melisabeth-fittschen\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/efi/Desktop/MasterArbeit/_0_mamba_vs_neo/src/mamba/wandb/run-20240527_232911-khruhcv4</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/khruhcv4' target=\"_blank\">mamba_run_512_tokens_6_epochs_no_silver</a></strong> to <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/khruhcv4' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/khruhcv4</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3372' max='3372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3372/3372 5:25:26, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Strict Accuracy</th>\n",
       "      <th>Hamming Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.122381</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.956293</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.297255</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>0.421111</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.229697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.107689</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.958659</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.296972</td>\n",
       "      <td>0.026174</td>\n",
       "      <td>0.470434</td>\n",
       "      <td>0.024648</td>\n",
       "      <td>0.216970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.094110</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.067642</td>\n",
       "      <td>0.490219</td>\n",
       "      <td>0.091834</td>\n",
       "      <td>0.667712</td>\n",
       "      <td>0.063485</td>\n",
       "      <td>0.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.085677</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.969780</td>\n",
       "      <td>0.093127</td>\n",
       "      <td>0.528359</td>\n",
       "      <td>0.145729</td>\n",
       "      <td>0.710338</td>\n",
       "      <td>0.077974</td>\n",
       "      <td>0.420606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.082664</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.970439</td>\n",
       "      <td>0.104257</td>\n",
       "      <td>0.557664</td>\n",
       "      <td>0.138818</td>\n",
       "      <td>0.700917</td>\n",
       "      <td>0.090861</td>\n",
       "      <td>0.463030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.971756</td>\n",
       "      <td>0.115184</td>\n",
       "      <td>0.586429</td>\n",
       "      <td>0.139213</td>\n",
       "      <td>0.713913</td>\n",
       "      <td>0.103006</td>\n",
       "      <td>0.497576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.079026</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.971732</td>\n",
       "      <td>0.118843</td>\n",
       "      <td>0.584141</td>\n",
       "      <td>0.152821</td>\n",
       "      <td>0.715919</td>\n",
       "      <td>0.104814</td>\n",
       "      <td>0.493333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.077372</td>\n",
       "      <td>0.321000</td>\n",
       "      <td>0.972854</td>\n",
       "      <td>0.124705</td>\n",
       "      <td>0.598630</td>\n",
       "      <td>0.163641</td>\n",
       "      <td>0.739092</td>\n",
       "      <td>0.108302</td>\n",
       "      <td>0.503030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.075399</td>\n",
       "      <td>0.343000</td>\n",
       "      <td>0.973634</td>\n",
       "      <td>0.135626</td>\n",
       "      <td>0.613514</td>\n",
       "      <td>0.176146</td>\n",
       "      <td>0.748038</td>\n",
       "      <td>0.120841</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.974439</td>\n",
       "      <td>0.138071</td>\n",
       "      <td>0.624103</td>\n",
       "      <td>0.181169</td>\n",
       "      <td>0.764499</td>\n",
       "      <td>0.122133</td>\n",
       "      <td>0.527273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.073608</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>0.973976</td>\n",
       "      <td>0.139155</td>\n",
       "      <td>0.624163</td>\n",
       "      <td>0.171334</td>\n",
       "      <td>0.745164</td>\n",
       "      <td>0.126140</td>\n",
       "      <td>0.536970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.072775</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.974805</td>\n",
       "      <td>0.153210</td>\n",
       "      <td>0.637162</td>\n",
       "      <td>0.209265</td>\n",
       "      <td>0.757728</td>\n",
       "      <td>0.134121</td>\n",
       "      <td>0.549697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.975049</td>\n",
       "      <td>0.163428</td>\n",
       "      <td>0.636848</td>\n",
       "      <td>0.212762</td>\n",
       "      <td>0.768638</td>\n",
       "      <td>0.142946</td>\n",
       "      <td>0.543636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.070786</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>0.975390</td>\n",
       "      <td>0.168638</td>\n",
       "      <td>0.645592</td>\n",
       "      <td>0.212741</td>\n",
       "      <td>0.767753</td>\n",
       "      <td>0.149539</td>\n",
       "      <td>0.556970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.072036</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.975463</td>\n",
       "      <td>0.172784</td>\n",
       "      <td>0.651179</td>\n",
       "      <td>0.218257</td>\n",
       "      <td>0.760940</td>\n",
       "      <td>0.153462</td>\n",
       "      <td>0.569091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.071188</td>\n",
       "      <td>0.389000</td>\n",
       "      <td>0.975561</td>\n",
       "      <td>0.175618</td>\n",
       "      <td>0.654483</td>\n",
       "      <td>0.212907</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>0.158128</td>\n",
       "      <td>0.575152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3372, training_loss=0.08599307818486314, metrics={'train_runtime': 19534.4487, 'train_samples_per_second': 2.764, 'train_steps_per_second': 0.173, 'total_flos': 1.998290794319493e+17, 'train_loss': 0.08599307818486314, 'epoch': 5.994666666666666})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:54:45.132239Z",
     "start_time": "2024-05-28T02:54:45.129485Z"
    }
   },
   "cell_type": "code",
   "source": "print(trainer)",
   "id": "b24da0c5397d09c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SimpleBCELossTrainer object at 0x7ff5b5e11b70>\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:56:30.598729Z",
     "start_time": "2024-05-28T02:54:45.133207Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(test)",
   "id": "5b4c111841d19ceb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.07208921760320663,\n",
       " 'eval_strict_accuracy': 0.421,\n",
       " 'eval_hamming_accuracy': 0.9753414634146341,\n",
       " 'eval_f1_macro': 0.15345974648025873,\n",
       " 'eval_f1_micro': 0.6453875833041038,\n",
       " 'eval_precision_macro': 0.20668286416975057,\n",
       " 'eval_precision_micro': 0.7931034482758621,\n",
       " 'eval_recall_macro': 0.1322420328399865,\n",
       " 'eval_recall_micro': 0.5440567711413364,\n",
       " 'eval_runtime': 105.4129,\n",
       " 'eval_samples_per_second': 9.487,\n",
       " 'eval_steps_per_second': 1.186,\n",
       " 'epoch': 5.994666666666666}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:58:15.874687Z",
     "start_time": "2024-05-28T02:56:30.599713Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = trainer.predict(test)",
   "id": "4d6cbf2282b280af",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:58:15.880238Z",
     "start_time": "2024-05-28T02:58:15.875779Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "8ee9ece7f37c6ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ -4.6086802 ,  -3.5544908 ,  -6.64375   , ...,  -8.15938   ,\n",
       "         -8.15938   ,  -8.15938   ],\n",
       "       [ -5.0444384 ,  -3.7203033 ,  -5.7259474 , ...,  -8.585681  ,\n",
       "         -8.585681  ,  -8.585681  ],\n",
       "       [ -5.581774  ,  -4.9260125 ,  -7.6950803 , ..., -10.603534  ,\n",
       "        -10.603534  , -10.603534  ],\n",
       "       ...,\n",
       "       [ -4.815941  ,   0.41324547,  -5.3264475 , ...,  -7.7252154 ,\n",
       "         -7.7252154 ,  -7.7252154 ],\n",
       "       [ -4.581134  ,  -0.406994  ,  -7.3289795 , ...,  -9.254812  ,\n",
       "         -9.254812  ,  -9.254812  ],\n",
       "       [ -4.9448485 ,  -3.463598  ,  -5.5648823 , ...,  -8.310236  ,\n",
       "         -8.310236  ,  -8.310236  ]], dtype=float32), label_ids=array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), metrics={'test_loss': 0.07208921760320663, 'test_strict_accuracy': 0.421, 'test_hamming_accuracy': 0.9753414634146341, 'test_f1_macro': 0.15345974648025873, 'test_f1_micro': 0.6453875833041038, 'test_precision_macro': 0.20668286416975057, 'test_precision_micro': 0.7931034482758621, 'test_recall_macro': 0.1322420328399865, 'test_recall_micro': 0.5440567711413364, 'test_runtime': 105.2704, 'test_samples_per_second': 9.499, 'test_steps_per_second': 1.187})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:58:15.890543Z",
     "start_time": "2024-05-28T02:58:15.881177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calulate_metrics_index(predictions, index):\n",
    "    logits = predictions.predictions\n",
    "    labels = predictions.label_ids\n",
    "    \n",
    "    logits = logits[:, index]\n",
    "    labels = labels[:, index]\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    count_correct = np.sum(labels)\n",
    "    count_predicted = np.sum(predictions)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'count_cases': count_correct,\n",
    "        'count_predicted': count_predicted\n",
    "    }\n"
   ],
   "id": "555e12e100ce0f50",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:58:15.899834Z",
     "start_time": "2024-05-28T02:58:15.891769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = utils_ecthr.ARTICLES_ID\n",
    "ids = {v: k for k, v in ids.items()}\n",
    "desc = utils_ecthr.ARTICLES_DESC\n"
   ],
   "id": "9e98169c432a3e5",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:58:15.985855Z",
     "start_time": "2024-05-28T02:58:15.900792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(0, 41):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Label {i}\")\n",
    "    print(ids[i])\n",
    "    print(desc[ids[i]])\n",
    "    print(calulate_metrics_index(predictions, i))"
   ],
   "id": "21914b194e6829cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Label 0\n",
      "2\n",
      "Right to life\n",
      "{'f1': 0.6666666666666666, 'precision': 0.7627118644067796, 'recall': 0.5921052631578947, 'count_cases': 76, 'count_predicted': 59}\n",
      "--------------------------------------------------\n",
      "Label 1\n",
      "3\n",
      "Prohibition of torture\n",
      "{'f1': 0.7320261437908496, 'precision': 0.7466666666666667, 'recall': 0.717948717948718, 'count_cases': 234, 'count_predicted': 225}\n",
      "--------------------------------------------------\n",
      "Label 2\n",
      "4\n",
      "Prohibition of slavery and forced labour\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 3\n",
      "5\n",
      "Right to liberty and security\n",
      "{'f1': 0.6827794561933535, 'precision': 0.837037037037037, 'recall': 0.576530612244898, 'count_cases': 196, 'count_predicted': 135}\n",
      "--------------------------------------------------\n",
      "Label 4\n",
      "6\n",
      "Right to a fair trial\n",
      "{'f1': 0.7472826086956522, 'precision': 0.804093567251462, 'recall': 0.6979695431472082, 'count_cases': 394, 'count_predicted': 342}\n",
      "--------------------------------------------------\n",
      "Label 5\n",
      "7\n",
      "No punishment without law\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 10, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 6\n",
      "8\n",
      "Right to respect for private and family life\n",
      "{'f1': 0.625, 'precision': 0.9, 'recall': 0.4787234042553192, 'count_cases': 188, 'count_predicted': 100}\n",
      "--------------------------------------------------\n",
      "Label 7\n",
      "9\n",
      "Freedom of thought, conscience and religion\n",
      "{'f1': 0.42857142857142855, 'precision': 1.0, 'recall': 0.2727272727272727, 'count_cases': 11, 'count_predicted': 3}\n",
      "--------------------------------------------------\n",
      "Label 8\n",
      "10\n",
      "Freedom of expression\n",
      "{'f1': 0.6910994764397905, 'precision': 0.7764705882352941, 'recall': 0.6226415094339622, 'count_cases': 106, 'count_predicted': 85}\n",
      "--------------------------------------------------\n",
      "Label 9\n",
      "11\n",
      "Freedom of assembly and association\n",
      "{'f1': 0.5915492957746479, 'precision': 0.75, 'recall': 0.4883720930232558, 'count_cases': 43, 'count_predicted': 28}\n",
      "--------------------------------------------------\n",
      "Label 10\n",
      "12\n",
      "Right to marry\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 4, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 11\n",
      "13\n",
      "Right to an effective remedy\n",
      "{'f1': 0.2236842105263158, 'precision': 0.5862068965517241, 'recall': 0.13821138211382114, 'count_cases': 123, 'count_predicted': 29}\n",
      "--------------------------------------------------\n",
      "Label 12\n",
      "14\n",
      "Prohibition of discrimination\n",
      "{'f1': 0.1111111111111111, 'precision': 0.5, 'recall': 0.0625, 'count_cases': 32, 'count_predicted': 4}\n",
      "--------------------------------------------------\n",
      "Label 13\n",
      "15\n",
      "Derogation in time of emergency\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 14\n",
      "16\n",
      "Restrictions on political activity of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 15\n",
      "17\n",
      "Prohibition of abuse of rights\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 16\n",
      "18\n",
      "Limitation on use of restrictions on rights\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 14, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 17\n",
      "34\n",
      "Individual applications\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 48, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 18\n",
      "38\n",
      "Examination of the case\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 19\n",
      "39\n",
      "Friendly settlements\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 20\n",
      "46\n",
      "Binding force and execution of judgments\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 21, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 21\n",
      "P1-1\n",
      "Protection of property\n",
      "{'f1': 0.7920792079207921, 'precision': 0.8108108108108109, 'recall': 0.7741935483870968, 'count_cases': 155, 'count_predicted': 148}\n",
      "--------------------------------------------------\n",
      "Label 22\n",
      "P1-2\n",
      "Right to education\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 5, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 23\n",
      "P1-3\n",
      "Right to free elections\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 2}\n",
      "--------------------------------------------------\n",
      "Label 24\n",
      "P3-1\n",
      "Right to free elections\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 25\n",
      "P4-1\n",
      "Prohibition of imprisonment for debt\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 26\n",
      "P4-2\n",
      "Freedom of movement\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 6, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 27\n",
      "P4-3\n",
      "Prohibition of expulsion of nationals\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 28\n",
      "P4-4\n",
      "Prohibition of collective expulsion of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 29\n",
      "P6-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 30\n",
      "P6-2\n",
      "Death penalty in time of war\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 31\n",
      "P6-3\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 32\n",
      "P7-1\n",
      "Procedural safeguards relating to expulsion of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 33\n",
      "P7-2\n",
      "Right of appeal in criminal matters\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 4, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 34\n",
      "P7-3\n",
      "Compensation for wrongful conviction\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 35\n",
      "P7-4\n",
      "Right not to be tried or punished twice\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 5, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 36\n",
      "P7-5\n",
      "Equality between spouses\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 37\n",
      "P12-1\n",
      "General prohibition of discrimination\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 38\n",
      "P13-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 39\n",
      "P13-2\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 40\n",
      "P13-3\n",
      "Prohibition of reservations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T02:58:15.990898Z",
     "start_time": "2024-05-28T02:58:15.986594Z"
    }
   },
   "cell_type": "code",
   "source": "calulate_metrics_index(predictions, 2)",
   "id": "98b38f03c11137fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'count_cases': 3,\n",
       " 'count_predicted': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
