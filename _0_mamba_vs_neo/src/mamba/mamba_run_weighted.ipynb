{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:37.661751Z",
     "start_time": "2024-05-26T21:13:35.525488Z"
    }
   },
   "source": [
    "from _0_mamba_vs_neo.models.MambaForSequenceClassification import MambaForSequenceClassification\n",
    "import _0_mamba_vs_neo.datasets.ecthr.utils_ecthr as utils_ecthr"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.152572Z",
     "start_time": "2024-05-26T21:13:37.662803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, hamming_loss\n",
    "import os"
   ],
   "id": "9fb2a38aeb33a5e2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.157910Z",
     "start_time": "2024-05-26T21:13:38.153477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "\n",
    "Here we will test how training the model with weighted BCE loss will affect the performance of the model.\n",
    "For speed we will use only sequences up to 512 tokens, but train for 6 epochs.\n",
    "\"\"\""
   ],
   "id": "ac5ed7f616dc4907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription:\\n\\nHere we will test how training the model with weighted BCE loss will affect the performance of the model.\\nFor speed we will use only sequences up to 512 tokens, but train for 6 epochs.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.166408Z",
     "start_time": "2024-05-26T21:13:38.158672Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"WANDB_PROJECT\"] = \"mamba_vs_neo_ecthr\"",
   "id": "e432f5a75cfa04ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.174198Z",
     "start_time": "2024-05-26T21:13:38.167717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CONFIGS:\n",
    "\"\"\""
   ],
   "id": "7302d5b13c10aea0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCONFIGS:\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.180979Z",
     "start_time": "2024-05-26T21:13:38.174933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    general:\n",
    "        - RUN_NAME: str\n",
    "            name of the run\n",
    "        - OUTPUT_DIR: str\n",
    "            directory to save the model and logs\n",
    "        - SEED: int\n",
    "            random seed to use\n",
    "        - REPORT_TO: str\n",
    "\"\"\"\n",
    "RUN_NAME = \"mamba_run_weighted_512_tokens_6_epochs\"\n",
    "OUTPUT_DIR = f\"_0_mamba_vs_neo/models/mamba/{RUN_NAME}\"\n",
    "SEED = 42\n",
    "REPORT_TO = \"wandb\""
   ],
   "id": "89a6f0a4fc3c0f0d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.188339Z",
     "start_time": "2024-05-26T21:13:38.181682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    dataset:\n",
    "        - ALLEGATIONS: bool\n",
    "            True: use allegation data for the cases, so what laws did the cases allegedly violate\n",
    "            False: use court decisions, so what laws did the court decide the cases violated\n",
    "        - SILVER: bool\n",
    "            True: only use facts which were deemed relevant by the court\n",
    "            False: use all facts\n",
    "        - MULTI_LABEL: bool\n",
    "            True: use multi-label classification (which law was (allegedly) violated)\n",
    "            False: use binary classification (was there a law (allegedly) violated)\n",
    "        - FREQUENCY_THRESHOLD: int\n",
    "            minimum number of cases a law must be (allegedly) violated in to be considered\n",
    "        - NUM_LABELS: int\n",
    "            number of labels in the dataset (ecthr: 41)\n",
    "        - MAX_LENGTH: int\n",
    "            maximum number of tokens in a sequence     \n",
    "\"\"\"\n",
    "ALLEGATIONS = True\n",
    "SILVER = True\n",
    "MULTI_LABEL = True\n",
    "FREQUENCY_THRESHOLD = 0\n",
    "NUM_LABELS = 41\n",
    "\n",
    "MAX_LENGTH = 512"
   ],
   "id": "6befe586279fd39c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.200964Z",
     "start_time": "2024-05-26T21:13:38.189270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    training:\n",
    "        - EPOCHS: int\n",
    "            number of times to iterate over the dataset\n",
    "        - LEARNING_RATE: float\n",
    "            rate at which the model learns\n",
    "        - BATCH_SIZE: int\n",
    "            number of sequences in a batch\n",
    "        - GRADIENT_ACCUMULATION_STEPS: int\n",
    "            number of batches to accumulate gradients over\n",
    "        - USE_LENGTH_GROUPING: bool\n",
    "            True: group sequences of similar length together to minimize padding\n",
    "            False: do not group sequences by length\n",
    "        - WARMUP_RATIO: float\n",
    "            ratio of training steps to warmup steps\n",
    "        - MAX_GRAD_NORM: float\n",
    "            maximum gradient norm to clip to\n",
    "        - WEIGHT_DECAY: float\n",
    "            weight decay to apply to the model\n",
    "\"\"\"\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 8\n",
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "print(\"true batch size:\", BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)\n",
    "\n",
    "WARMUP_RATIO = 0.1\n",
    "MAX_GRAD_NORM = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "\n",
    "USE_LENGTH_GROUPING = True"
   ],
   "id": "893de6da13f235d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true batch size: 16\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.208344Z",
     "start_time": "2024-05-26T21:13:38.201751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    evaluation:\n",
    "        - EVAL_STEPS: int\n",
    "            number of steps between evaluations\n",
    "        - BATCH_SIZE_EVAL: int\n",
    "            number of sequences in a batch for evaluation\n",
    "        - LOGGING_STEPS: int\n",
    "            number of steps between logging\n",
    "        - EVAL_ACCUMULATION_STEPS: int\n",
    "            number eval batches to calculate before copying to the cpu, if the eval requires a lot of memory this is helpful\n",
    "\"\"\"\n",
    "EVAL_STEPS = 200\n",
    "BATCH_SIZE_EVAL = BATCH_SIZE\n",
    "LOGGING_STEPS = 100\n",
    "EVAL_ACCUMULATION_STEPS = 20"
   ],
   "id": "baba926e7f85c13b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.216547Z",
     "start_time": "2024-05-26T21:13:38.209034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    model:\n",
    "        - MODEL_NAME: str\n",
    "            name of the model to use\n",
    "        - LORA_TASK_TYPE:\n",
    "        - LORA_R: int\n",
    "           r is the rank of the approximation\n",
    "        - LORA_TARGET_MODULES: list\n",
    "            list of modules to target with LoRA\n",
    "\"\"\"\n",
    "MODEL_NAME = \"state-spaces/mamba-1.4b-hf\"\n",
    "LORA_TASK_TYPE = TaskType.SEQ_CLS\n",
    "LORA_R = 8\n",
    "LORA_TARGET_MODULES = [\"x_proj\", \"embeddings\", \"in_proj\", \"out_proj\"]"
   ],
   "id": "a1937d47960adb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.224774Z",
     "start_time": "2024-05-26T21:13:38.217377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    \n",
    "    precision_macro, recall_macto, f1_macro, _ = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, predictions, average='micro', zero_division=0)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'strict_accuracy': accuracy,\n",
    "        'hamming_accuracy': 1 - hamming_loss(labels, predictions),\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_macro': recall_macto,\n",
    "        'recall_micro': recall_micro\n",
    "    }"
   ],
   "id": "ca5335c6d3836d38",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:38.232065Z",
     "start_time": "2024-05-26T21:13:38.225516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WeightedBCELossTrainer(Trainer):\n",
    "    def __init__(self, *args, weight=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = self.loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "id": "a5429b5b3fa7540c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:39.518671Z",
     "start_time": "2024-05-26T21:13:38.232814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MambaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\")"
   ],
   "id": "6267f525c2c7421f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2b0673075644b668d4baaa0f284f320"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MambaForSequenceClassification were not initialized from the model checkpoint at state-spaces/mamba-1.4b-hf and are newly initialized: ['backbone.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:39.523062Z",
     "start_time": "2024-05-26T21:13:39.520979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "58d4063fa0ee2176",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:39.531968Z",
     "start_time": "2024-05-26T21:13:39.523855Z"
    }
   },
   "cell_type": "code",
   "source": "collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = True)",
   "id": "8b1592b4547f7fc9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:42.743607Z",
     "start_time": "2024-05-26T21:13:39.532741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ecthr_dataset = utils_ecthr.load_ecthr_dataset(allegations=ALLEGATIONS, silver=SILVER, is_multi_label=MULTI_LABEL, frequency_threshold=FREQUENCY_THRESHOLD)\n",
    "ecthr_dataset = utils_ecthr.tokenize_dataset(ecthr_dataset, tokenizer, max_length=MAX_LENGTH)\n",
    "ecthr_dataset = ecthr_dataset.remove_columns(\"facts\")"
   ],
   "id": "cc2df7d0da5e4328",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:42.746692Z",
     "start_time": "2024-05-26T21:13:42.744355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = ecthr_dataset[\"train\"]\n",
    "val = ecthr_dataset[\"validation\"]\n",
    "test = ecthr_dataset[\"test\"]"
   ],
   "id": "43a3d065e7e80583",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:42.755492Z",
     "start_time": "2024-05-26T21:13:42.747412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config =  LoraConfig(\n",
    "        r=LORA_R,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        task_type=LORA_TASK_TYPE,\n",
    "        bias=\"none\"\n",
    ")"
   ],
   "id": "79702f6a279249d1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:42.907209Z",
     "start_time": "2024-05-26T21:13:42.756210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "56fe4e927b2759d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,428,352 || all params: 1,380,690,752 || trainable%: 0.6104\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.783119Z",
     "start_time": "2024-05-26T21:13:42.908152Z"
    }
   },
   "cell_type": "code",
   "source": "model.to(\"cuda\")",
   "id": "bccf92a23ac3a46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MambaForSequenceClassification(\n",
       "      (embeddings): lora.Embedding(\n",
       "        (base_layer): Embedding(50280, 2048)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict()\n",
       "        (lora_B): ModuleDict()\n",
       "        (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 8x50280 (cuda:0)])\n",
       "        (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (cuda:0)])\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-47): 48 x MambaBlock(\n",
       "          (norm): MambaRMSNorm()\n",
       "          (mixer): MambaMixer(\n",
       "            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)\n",
       "            (act): SiLU()\n",
       "            (in_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (x_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=160, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=160, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (dt_proj): Linear(in_features=128, out_features=4096, bias=True)\n",
       "            (out_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): MambaRMSNorm()\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.790149Z",
     "start_time": "2024-05-26T21:13:43.783894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ],
   "id": "cbc50cb119f59b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.embeddings.lora_embedding_A.default\n",
      "base_model.model.embeddings.lora_embedding_B.default\n",
      "base_model.model.layers.0.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.classifier.modules_to_save.default.weight\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.832243Z",
     "start_time": "2024-05-26T21:13:43.790936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= OUTPUT_DIR,\n",
    "    run_name= RUN_NAME,\n",
    "    learning_rate= LEARNING_RATE,\n",
    "    lr_scheduler_type= \"constant\",\n",
    "    warmup_ratio= WARMUP_RATIO,\n",
    "    max_grad_norm= MAX_GRAD_NORM,\n",
    "    per_device_train_batch_size= BATCH_SIZE,\n",
    "    per_device_eval_batch_size= BATCH_SIZE_EVAL,\n",
    "    gradient_accumulation_steps= GRADIENT_ACCUMULATION_STEPS,#\n",
    "    group_by_length= USE_LENGTH_GROUPING,\n",
    "    num_train_epochs= EPOCHS,\n",
    "    weight_decay= WEIGHT_DECAY,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps= EVAL_STEPS,\n",
    "    eval_accumulation_steps = EVAL_ACCUMULATION_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps= EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to= REPORT_TO,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps= LOGGING_STEPS,\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ],
   "id": "4aea53a3acaa584f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.936163Z",
     "start_time": "2024-05-26T21:13:43.833047Z"
    }
   },
   "cell_type": "code",
   "source": "labels = train[\"labels\"]",
   "id": "f3378fbf5543a8c",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.971287Z",
     "start_time": "2024-05-26T21:13:43.936916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make labels torch:\n",
    "labels = torch.tensor(labels)\n",
    "num_positives = labels.sum(dim=0)\n",
    "num_negatives = len(labels) - num_positives\n",
    "pos_weight = num_negatives.float() / num_positives.float()\n",
    "pos_weight[torch.isinf(pos_weight)] = 1.0\n"
   ],
   "id": "ba6b747ad55b5a18",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.979610Z",
     "start_time": "2024-05-26T21:13:43.972066Z"
    }
   },
   "cell_type": "code",
   "source": "num_positives",
   "id": "aeddcc58e9ab3c37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 623, 1740,   26, 1623, 5437,   72, 1056,   81,  441,  162,   16, 1665,\n",
       "         444,    6,    0,   31,   42,  547,  119,  159,  187, 1558,   15,   61,\n",
       "           1,    0,   48,    0,    7,    0,    0,    1,    7,   17,    1,   29,\n",
       "           2,    5,    0,    0,    0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.987434Z",
     "start_time": "2024-05-26T21:13:43.980317Z"
    }
   },
   "cell_type": "code",
   "source": "num_negatives",
   "id": "b1f7da6a2e9ad957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8377, 7260, 8974, 7377, 3563, 8928, 7944, 8919, 8559, 8838, 8984, 7335,\n",
       "        8556, 8994, 9000, 8969, 8958, 8453, 8881, 8841, 8813, 7442, 8985, 8939,\n",
       "        8999, 9000, 8952, 9000, 8993, 9000, 9000, 8999, 8993, 8983, 8999, 8971,\n",
       "        8998, 8995, 9000, 9000, 9000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:43.994693Z",
     "start_time": "2024-05-26T21:13:43.988062Z"
    }
   },
   "cell_type": "code",
   "source": "pos_weight",
   "id": "a393fbfb74f64e6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3446e+01, 4.1724e+00, 3.4515e+02, 4.5453e+00, 6.5532e-01, 1.2400e+02,\n",
       "        7.5227e+00, 1.1011e+02, 1.9408e+01, 5.4556e+01, 5.6150e+02, 4.4054e+00,\n",
       "        1.9270e+01, 1.4990e+03, 1.0000e+00, 2.8932e+02, 2.1329e+02, 1.5453e+01,\n",
       "        7.4630e+01, 5.5604e+01, 4.7128e+01, 4.7766e+00, 5.9900e+02, 1.4654e+02,\n",
       "        8.9990e+03, 1.0000e+00, 1.8650e+02, 1.0000e+00, 1.2847e+03, 1.0000e+00,\n",
       "        1.0000e+00, 8.9990e+03, 1.2847e+03, 5.2841e+02, 8.9990e+03, 3.0934e+02,\n",
       "        4.4990e+03, 1.7990e+03, 1.0000e+00, 1.0000e+00, 1.0000e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:13:44.155196Z",
     "start_time": "2024-05-26T21:13:43.995387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = WeightedBCELossTrainer(\n",
    "    weight=pos_weight.to(\"cuda\"),\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "33280cfe33e287e1",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T01:58:03.243113Z",
     "start_time": "2024-05-26T21:13:44.155989Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "db97522ffc2fbbd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33melisabeth-fittschen\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/efi/Desktop/MasterArbeit/_0_mamba_vs_neo/src/mamba/wandb/run-20240526_231347-8byvkpnv</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/8byvkpnv' target=\"_blank\">mamba_run_weighted_512_tokens_6_epochs</a></strong> to <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/8byvkpnv' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/8byvkpnv</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3372' max='3372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3372/3372 4:44:09, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Strict Accuracy</th>\n",
       "      <th>Hamming Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.036900</td>\n",
       "      <td>1.584261</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.930171</td>\n",
       "      <td>0.074029</td>\n",
       "      <td>0.383373</td>\n",
       "      <td>0.063058</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>0.106422</td>\n",
       "      <td>0.539394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.890600</td>\n",
       "      <td>1.981325</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.943171</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.431984</td>\n",
       "      <td>0.069702</td>\n",
       "      <td>0.361338</td>\n",
       "      <td>0.106163</td>\n",
       "      <td>0.536970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.048500</td>\n",
       "      <td>1.914950</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.923195</td>\n",
       "      <td>0.102383</td>\n",
       "      <td>0.409082</td>\n",
       "      <td>0.084207</td>\n",
       "      <td>0.296276</td>\n",
       "      <td>0.168236</td>\n",
       "      <td>0.660606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.389300</td>\n",
       "      <td>1.759286</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.915024</td>\n",
       "      <td>0.120466</td>\n",
       "      <td>0.402196</td>\n",
       "      <td>0.088826</td>\n",
       "      <td>0.280517</td>\n",
       "      <td>0.263728</td>\n",
       "      <td>0.710303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.852800</td>\n",
       "      <td>1.764620</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.913098</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>0.406661</td>\n",
       "      <td>0.096367</td>\n",
       "      <td>0.280367</td>\n",
       "      <td>0.277682</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>1.633213</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.906415</td>\n",
       "      <td>0.127928</td>\n",
       "      <td>0.390275</td>\n",
       "      <td>0.096436</td>\n",
       "      <td>0.264484</td>\n",
       "      <td>0.290291</td>\n",
       "      <td>0.744242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.093700</td>\n",
       "      <td>1.631404</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.921585</td>\n",
       "      <td>0.138094</td>\n",
       "      <td>0.431678</td>\n",
       "      <td>0.105019</td>\n",
       "      <td>0.304717</td>\n",
       "      <td>0.281983</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.616700</td>\n",
       "      <td>1.658565</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.935244</td>\n",
       "      <td>0.150332</td>\n",
       "      <td>0.473110</td>\n",
       "      <td>0.116455</td>\n",
       "      <td>0.351726</td>\n",
       "      <td>0.275330</td>\n",
       "      <td>0.722424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.831300</td>\n",
       "      <td>1.291687</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.919195</td>\n",
       "      <td>0.159579</td>\n",
       "      <td>0.425325</td>\n",
       "      <td>0.118118</td>\n",
       "      <td>0.297934</td>\n",
       "      <td>0.369758</td>\n",
       "      <td>0.743030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.074300</td>\n",
       "      <td>1.418048</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.924146</td>\n",
       "      <td>0.163807</td>\n",
       "      <td>0.439438</td>\n",
       "      <td>0.124548</td>\n",
       "      <td>0.312724</td>\n",
       "      <td>0.336466</td>\n",
       "      <td>0.738788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>1.501181</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.930488</td>\n",
       "      <td>0.170510</td>\n",
       "      <td>0.461655</td>\n",
       "      <td>0.131608</td>\n",
       "      <td>0.335346</td>\n",
       "      <td>0.334684</td>\n",
       "      <td>0.740606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>1.403564</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.930854</td>\n",
       "      <td>0.177886</td>\n",
       "      <td>0.462763</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>0.336642</td>\n",
       "      <td>0.348889</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.641100</td>\n",
       "      <td>1.317244</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.930171</td>\n",
       "      <td>0.174103</td>\n",
       "      <td>0.460117</td>\n",
       "      <td>0.132396</td>\n",
       "      <td>0.333972</td>\n",
       "      <td>0.367738</td>\n",
       "      <td>0.739394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.624100</td>\n",
       "      <td>1.369692</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.928488</td>\n",
       "      <td>0.175724</td>\n",
       "      <td>0.457840</td>\n",
       "      <td>0.130389</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.403374</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>1.394881</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.930293</td>\n",
       "      <td>0.175428</td>\n",
       "      <td>0.462782</td>\n",
       "      <td>0.131841</td>\n",
       "      <td>0.335422</td>\n",
       "      <td>0.402674</td>\n",
       "      <td>0.746061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>1.585215</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.927878</td>\n",
       "      <td>0.179684</td>\n",
       "      <td>0.454931</td>\n",
       "      <td>0.136171</td>\n",
       "      <td>0.326887</td>\n",
       "      <td>0.382616</td>\n",
       "      <td>0.747879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3372, training_loss=1.047440564505146, metrics={'train_runtime': 17056.7804, 'train_samples_per_second': 3.166, 'train_steps_per_second': 0.198, 'total_flos': 1.702218752087163e+17, 'train_loss': 1.047440564505146, 'epoch': 5.994666666666666})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T01:58:03.246924Z",
     "start_time": "2024-05-27T01:58:03.243953Z"
    }
   },
   "cell_type": "code",
   "source": "print(trainer)",
   "id": "b24da0c5397d09c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.WeightedBCELossTrainer object at 0x7f83d0230eb0>\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T01:59:48.494595Z",
     "start_time": "2024-05-27T01:58:03.247822Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(test)",
   "id": "5b4c111841d19ceb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.6794471740722656,\n",
       " 'eval_strict_accuracy': 0.066,\n",
       " 'eval_hamming_accuracy': 0.9121707317073171,\n",
       " 'eval_f1_macro': 0.14599509621044499,\n",
       " 'eval_f1_micro': 0.4070475876831879,\n",
       " 'eval_precision_macro': 0.11024248968984837,\n",
       " 'eval_precision_micro': 0.2820629849383843,\n",
       " 'eval_recall_macro': 0.3498547274539948,\n",
       " 'eval_recall_micro': 0.7309284447072738,\n",
       " 'eval_runtime': 105.2343,\n",
       " 'eval_samples_per_second': 9.503,\n",
       " 'eval_steps_per_second': 1.188,\n",
       " 'epoch': 5.994666666666666}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:01:33.751978Z",
     "start_time": "2024-05-27T01:59:48.495439Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = trainer.predict(test)",
   "id": "4d6cbf2282b280af",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:01:33.756534Z",
     "start_time": "2024-05-27T02:01:33.752958Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "8ee9ece7f37c6ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.806864  , -2.3981493 , -2.6462197 , ..., -6.029908  ,\n",
       "        -6.029908  , -6.029908  ],\n",
       "       [-1.4677405 , -1.8144476 , -2.4256995 , ..., -7.036352  ,\n",
       "        -7.036352  , -7.036352  ],\n",
       "       [-2.2026987 , -2.365809  , -2.1277614 , ..., -5.0918813 ,\n",
       "        -5.0918813 , -5.0918813 ],\n",
       "       ...,\n",
       "       [-0.38720113, -0.90709853, -2.1523602 , ..., -5.989273  ,\n",
       "        -5.989273  , -5.989273  ],\n",
       "       [ 0.48376253,  2.9684055 , -3.400179  , ..., -6.8790054 ,\n",
       "        -6.8790054 , -6.8790054 ],\n",
       "       [-0.40080598,  3.2161222 , -3.1352289 , ..., -6.5014496 ,\n",
       "        -6.5014496 , -6.5014496 ]], dtype=float32), label_ids=array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), metrics={'test_loss': 3.6794471740722656, 'test_strict_accuracy': 0.066, 'test_hamming_accuracy': 0.9121707317073171, 'test_f1_macro': 0.14599509621044499, 'test_f1_micro': 0.4070475876831879, 'test_precision_macro': 0.11024248968984837, 'test_precision_micro': 0.2820629849383843, 'test_recall_macro': 0.3498547274539948, 'test_recall_micro': 0.7309284447072738, 'test_runtime': 105.2521, 'test_samples_per_second': 9.501, 'test_steps_per_second': 1.188})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:01:33.835960Z",
     "start_time": "2024-05-27T02:01:33.757245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calulate_metrics_index(predictions, index):\n",
    "    logits = predictions.predictions\n",
    "    labels = predictions.label_ids\n",
    "    \n",
    "    logits = logits[:, index]\n",
    "    labels = labels[:, index]\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    count_correct = np.sum(labels)\n",
    "    count_predicted = np.sum(predictions)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'count_cases': count_correct,\n",
    "        'count_predicted': count_predicted\n",
    "    }\n"
   ],
   "id": "555e12e100ce0f50",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:01:33.898454Z",
     "start_time": "2024-05-27T02:01:33.836907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = utils_ecthr.ARTICLES_ID\n",
    "ids = {v: k for k, v in ids.items()}\n",
    "desc = utils_ecthr.ARTICLES_DESC\n"
   ],
   "id": "9e98169c432a3e5",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:01:34.023838Z",
     "start_time": "2024-05-27T02:01:33.899465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# starting at 1 because 0 is not occupied due to an indexing error\n",
    "for i in range(1, 41):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Label {i}\")\n",
    "    print(ids[i])\n",
    "    print(desc[ids[i]])\n",
    "    print(calulate_metrics_index(predictions, i))"
   ],
   "id": "21914b194e6829cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Label 1\n",
      "3\n",
      "Prohibition of torture\n",
      "{'f1': 0.6261127596439169, 'precision': 0.47954545454545455, 'recall': 0.9017094017094017, 'count_cases': 234, 'count_predicted': 440}\n",
      "--------------------------------------------------\n",
      "Label 2\n",
      "4\n",
      "Prohibition of slavery and forced labour\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 1}\n",
      "--------------------------------------------------\n",
      "Label 3\n",
      "5\n",
      "Right to liberty and security\n",
      "{'f1': 0.5936920222634509, 'precision': 0.46647230320699706, 'recall': 0.8163265306122449, 'count_cases': 196, 'count_predicted': 343}\n",
      "--------------------------------------------------\n",
      "Label 4\n",
      "6\n",
      "Right to a fair trial\n",
      "{'f1': 0.6190476190476191, 'precision': 0.690625, 'recall': 0.5609137055837563, 'count_cases': 394, 'count_predicted': 320}\n",
      "--------------------------------------------------\n",
      "Label 5\n",
      "7\n",
      "No punishment without law\n",
      "{'f1': 0.05660377358490566, 'precision': 0.03125, 'recall': 0.3, 'count_cases': 10, 'count_predicted': 96}\n",
      "--------------------------------------------------\n",
      "Label 6\n",
      "8\n",
      "Right to respect for private and family life\n",
      "{'f1': 0.5141955835962145, 'precision': 0.3654708520179372, 'recall': 0.8670212765957447, 'count_cases': 188, 'count_predicted': 446}\n",
      "--------------------------------------------------\n",
      "Label 7\n",
      "9\n",
      "Freedom of thought, conscience and religion\n",
      "{'f1': 0.12080536912751678, 'precision': 0.06521739130434782, 'recall': 0.8181818181818182, 'count_cases': 11, 'count_predicted': 138}\n",
      "--------------------------------------------------\n",
      "Label 8\n",
      "10\n",
      "Freedom of expression\n",
      "{'f1': 0.5849056603773585, 'precision': 0.4386792452830189, 'recall': 0.8773584905660378, 'count_cases': 106, 'count_predicted': 212}\n",
      "--------------------------------------------------\n",
      "Label 9\n",
      "11\n",
      "Freedom of assembly and association\n",
      "{'f1': 0.330188679245283, 'precision': 0.20710059171597633, 'recall': 0.813953488372093, 'count_cases': 43, 'count_predicted': 169}\n",
      "--------------------------------------------------\n",
      "Label 10\n",
      "12\n",
      "Right to marry\n",
      "{'f1': 0.16666666666666666, 'precision': 0.09375, 'recall': 0.75, 'count_cases': 4, 'count_predicted': 32}\n",
      "--------------------------------------------------\n",
      "Label 11\n",
      "13\n",
      "Right to an effective remedy\n",
      "{'f1': 0.29280397022332505, 'precision': 0.21071428571428572, 'recall': 0.4796747967479675, 'count_cases': 123, 'count_predicted': 280}\n",
      "--------------------------------------------------\n",
      "Label 12\n",
      "14\n",
      "Prohibition of discrimination\n",
      "{'f1': 0.14814814814814814, 'precision': 0.08150470219435736, 'recall': 0.8125, 'count_cases': 32, 'count_predicted': 319}\n",
      "--------------------------------------------------\n",
      "Label 13\n",
      "15\n",
      "Derogation in time of emergency\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 14\n",
      "16\n",
      "Restrictions on political activity of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 15\n",
      "17\n",
      "Prohibition of abuse of rights\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 16\n",
      "18\n",
      "Limitation on use of restrictions on rights\n",
      "{'f1': 0.13636363636363635, 'precision': 0.08108108108108109, 'recall': 0.42857142857142855, 'count_cases': 14, 'count_predicted': 74}\n",
      "--------------------------------------------------\n",
      "Label 17\n",
      "34\n",
      "Individual applications\n",
      "{'f1': 0.13026819923371646, 'precision': 0.07172995780590717, 'recall': 0.7083333333333334, 'count_cases': 48, 'count_predicted': 474}\n",
      "--------------------------------------------------\n",
      "Label 18\n",
      "38\n",
      "Examination of the case\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 61}\n",
      "--------------------------------------------------\n",
      "Label 19\n",
      "39\n",
      "Friendly settlements\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 10}\n",
      "--------------------------------------------------\n",
      "Label 20\n",
      "46\n",
      "Binding force and execution of judgments\n",
      "{'f1': 0.060810810810810814, 'precision': 0.03272727272727273, 'recall': 0.42857142857142855, 'count_cases': 21, 'count_predicted': 275}\n",
      "--------------------------------------------------\n",
      "Label 21\n",
      "P1-1\n",
      "Protection of property\n",
      "{'f1': 0.7411444141689373, 'precision': 0.6415094339622641, 'recall': 0.8774193548387097, 'count_cases': 155, 'count_predicted': 212}\n",
      "--------------------------------------------------\n",
      "Label 22\n",
      "P1-2\n",
      "Right to education\n",
      "{'f1': 0.14285714285714285, 'precision': 0.07692307692307693, 'recall': 1.0, 'count_cases': 5, 'count_predicted': 65}\n",
      "--------------------------------------------------\n",
      "Label 23\n",
      "P1-3\n",
      "Right to free elections\n",
      "{'f1': 0.030303030303030304, 'precision': 0.015384615384615385, 'recall': 1.0, 'count_cases': 2, 'count_predicted': 130}\n",
      "--------------------------------------------------\n",
      "Label 24\n",
      "P3-1\n",
      "Right to free elections\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 25\n",
      "P4-1\n",
      "Prohibition of imprisonment for debt\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 26\n",
      "P4-2\n",
      "Freedom of movement\n",
      "{'f1': 0.11428571428571428, 'precision': 0.0625, 'recall': 0.6666666666666666, 'count_cases': 6, 'count_predicted': 64}\n",
      "--------------------------------------------------\n",
      "Label 27\n",
      "P4-3\n",
      "Prohibition of expulsion of nationals\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 28\n",
      "P4-4\n",
      "Prohibition of collective expulsion of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 4}\n",
      "--------------------------------------------------\n",
      "Label 29\n",
      "P6-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 30\n",
      "P6-2\n",
      "Death penalty in time of war\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 31\n",
      "P6-3\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 32\n",
      "P7-1\n",
      "Procedural safeguards relating to expulsion of aliens\n",
      "{'f1': 0.1, 'precision': 0.05555555555555555, 'recall': 0.5, 'count_cases': 2, 'count_predicted': 18}\n",
      "--------------------------------------------------\n",
      "Label 33\n",
      "P7-2\n",
      "Right of appeal in criminal matters\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 4, 'count_predicted': 34}\n",
      "--------------------------------------------------\n",
      "Label 34\n",
      "P7-3\n",
      "Compensation for wrongful conviction\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 35\n",
      "P7-4\n",
      "Right not to be tried or punished twice\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 5, 'count_predicted': 2}\n",
      "--------------------------------------------------\n",
      "Label 36\n",
      "P7-5\n",
      "Equality between spouses\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 37\n",
      "P12-1\n",
      "General prohibition of discrimination\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 4}\n",
      "--------------------------------------------------\n",
      "Label 38\n",
      "P13-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 39\n",
      "P13-2\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 40\n",
      "P13-3\n",
      "Prohibition of reservations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:01:34.029143Z",
     "start_time": "2024-05-27T02:01:34.024612Z"
    }
   },
   "cell_type": "code",
   "source": "calulate_metrics_index(predictions, 2)",
   "id": "98b38f03c11137fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'count_cases': 3,\n",
       " 'count_predicted': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T02:01:34.031499Z",
     "start_time": "2024-05-27T02:01:34.029865Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\" It seems like the weights are too high for unimportant labels, so we might have to do more research\"\"\"",
   "id": "60912f3099c12ec8",
   "outputs": [],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
