{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.413442Z",
     "start_time": "2024-05-28T18:33:15.368642Z"
    }
   },
   "source": [
    "from _0_mamba_vs_neo.models.MambaForSequenceClassification import MambaForSequenceClassification\n",
    "import _0_mamba_vs_neo.datasets.ecthr.utils_ecthr as utils_ecthr"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.916518Z",
     "start_time": "2024-05-28T18:33:17.414619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, hamming_loss\n",
    "import os"
   ],
   "id": "9fb2a38aeb33a5e2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.921812Z",
     "start_time": "2024-05-28T18:33:17.917273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "\n",
    "Train for 6 epochs with 3000 tokens without silver data, as to trying to improve our current results.\n",
    "\"\"\""
   ],
   "id": "ac5ed7f616dc4907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription:\\n\\nTrain for 6 epochs with 3000 tokens without silver data, as to trying to improve our current results.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.929469Z",
     "start_time": "2024-05-28T18:33:17.922977Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"WANDB_PROJECT\"] = \"mamba_vs_neo_ecthr\"",
   "id": "e432f5a75cfa04ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.937732Z",
     "start_time": "2024-05-28T18:33:17.930908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CONFIGS:\n",
    "\"\"\""
   ],
   "id": "7302d5b13c10aea0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCONFIGS:\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.944597Z",
     "start_time": "2024-05-28T18:33:17.938605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    general:\n",
    "        - RUN_NAME: str\n",
    "            name of the run\n",
    "        - OUTPUT_DIR: str\n",
    "            directory to save the model and logs\n",
    "        - SEED: int\n",
    "            random seed to use\n",
    "        - REPORT_TO: str\n",
    "\"\"\"\n",
    "RUN_NAME = \"mamba_run_512_tokens_6_epochs_no_silver_3000\"\n",
    "OUTPUT_DIR = f\"_0_mamba_vs_neo/models/mamba/{RUN_NAME}\"\n",
    "SEED = 42\n",
    "REPORT_TO = \"wandb\""
   ],
   "id": "89a6f0a4fc3c0f0d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.952674Z",
     "start_time": "2024-05-28T18:33:17.945433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    dataset:\n",
    "        - ALLEGATIONS: bool\n",
    "            True: use allegation data for the cases, so what laws did the cases allegedly violate\n",
    "            False: use court decisions, so what laws did the court decide the cases violated\n",
    "        - SILVER: bool\n",
    "            True: only use facts which were deemed relevant by the court\n",
    "            False: use all facts\n",
    "        - MULTI_LABEL: bool\n",
    "            True: use multi-label classification (which law was (allegedly) violated)\n",
    "            False: use binary classification (was there a law (allegedly) violated)\n",
    "        - FREQUENCY_THRESHOLD: int\n",
    "            minimum number of cases a law must be (allegedly) violated in to be considered\n",
    "        - NUM_LABELS: int\n",
    "            number of labels in the dataset (ecthr: 41)\n",
    "        - MAX_LENGTH: int\n",
    "            maximum number of tokens in a sequence     \n",
    "\"\"\"\n",
    "ALLEGATIONS = True\n",
    "SILVER = False\n",
    "MULTI_LABEL = True\n",
    "FREQUENCY_THRESHOLD = 0\n",
    "NUM_LABELS = 41\n",
    "\n",
    "MAX_LENGTH = 3000"
   ],
   "id": "6befe586279fd39c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.961920Z",
     "start_time": "2024-05-28T18:33:17.953614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    training:\n",
    "        - EPOCHS: int\n",
    "            number of times to iterate over the dataset\n",
    "        - LEARNING_RATE: float\n",
    "            rate at which the model learns\n",
    "        - BATCH_SIZE: int\n",
    "            number of sequences in a batch\n",
    "        - GRADIENT_ACCUMULATION_STEPS: int\n",
    "            number of batches to accumulate gradients over\n",
    "        - USE_LENGTH_GROUPING: bool\n",
    "            True: group sequences of similar length together to minimize padding\n",
    "            False: do not group sequences by length\n",
    "        - WARMUP_RATIO: float\n",
    "            ratio of training steps to warmup steps\n",
    "        - MAX_GRAD_NORM: float\n",
    "            maximum gradient norm to clip to\n",
    "        - WEIGHT_DECAY: float\n",
    "            weight decay to apply to the model\n",
    "\"\"\"\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 8\n",
    "print(\"true batch size:\", BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)\n",
    "\n",
    "WARMUP_RATIO = 0.1\n",
    "MAX_GRAD_NORM = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "\n",
    "USE_LENGTH_GROUPING = True"
   ],
   "id": "893de6da13f235d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true batch size: 16\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.969852Z",
     "start_time": "2024-05-28T18:33:17.962776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    evaluation:\n",
    "        - EVAL_STEPS: int\n",
    "            number of steps between evaluations\n",
    "        - BATCH_SIZE_EVAL: int\n",
    "            number of sequences in a batch for evaluation\n",
    "        - LOGGING_STEPS: int\n",
    "            number of steps between logging\n",
    "        - EVAL_ACCUMULATION_STEPS: int\n",
    "            number eval batches to calculate before copying to the cpu, if the eval requires a lot of memory this is helpful\n",
    "\"\"\"\n",
    "EVAL_STEPS = 200\n",
    "BATCH_SIZE_EVAL = BATCH_SIZE\n",
    "LOGGING_STEPS = 100\n",
    "EVAL_ACCUMULATION_STEPS = 20"
   ],
   "id": "baba926e7f85c13b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.977255Z",
     "start_time": "2024-05-28T18:33:17.970658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    model:\n",
    "        - MODEL_NAME: str\n",
    "            name of the model to use\n",
    "        - LORA_TASK_TYPE:\n",
    "        - LORA_R: int\n",
    "           r is the rank of the approximation\n",
    "        - LORA_TARGET_MODULES: list\n",
    "            list of modules to target with LoRA\n",
    "\"\"\"\n",
    "MODEL_NAME = \"state-spaces/mamba-1.4b-hf\"\n",
    "LORA_TASK_TYPE = TaskType.SEQ_CLS\n",
    "LORA_R = 8\n",
    "LORA_TARGET_MODULES = [\"x_proj\", \"embeddings\", \"in_proj\", \"out_proj\"]"
   ],
   "id": "a1937d47960adb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.984948Z",
     "start_time": "2024-05-28T18:33:17.978010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    \n",
    "    precision_macro, recall_macto, f1_macro, _ = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, predictions, average='micro', zero_division=0)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'strict_accuracy': accuracy,\n",
    "        'hamming_accuracy': 1 - hamming_loss(labels, predictions),\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_macro': recall_macto,\n",
    "        'recall_micro': recall_micro\n",
    "    }"
   ],
   "id": "ca5335c6d3836d38",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:17.993559Z",
     "start_time": "2024-05-28T18:33:17.985699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleBCELossTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = self.loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "id": "a5429b5b3fa7540c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:19.473363Z",
     "start_time": "2024-05-28T18:33:17.994286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MambaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\")"
   ],
   "id": "6267f525c2c7421f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bad50d858c64018adf2f192fcca85b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MambaForSequenceClassification were not initialized from the model checkpoint at state-spaces/mamba-1.4b-hf and are newly initialized: ['backbone.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:19.478165Z",
     "start_time": "2024-05-28T18:33:19.475975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "58d4063fa0ee2176",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:19.486943Z",
     "start_time": "2024-05-28T18:33:19.479121Z"
    }
   },
   "cell_type": "code",
   "source": "collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = True)",
   "id": "8b1592b4547f7fc9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:24.244240Z",
     "start_time": "2024-05-28T18:33:19.487803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ecthr_dataset = utils_ecthr.load_ecthr_dataset(allegations=ALLEGATIONS, silver=SILVER, is_multi_label=MULTI_LABEL, frequency_threshold=FREQUENCY_THRESHOLD)\n",
    "ecthr_dataset = utils_ecthr.tokenize_dataset(ecthr_dataset, tokenizer, max_length=MAX_LENGTH)\n",
    "ecthr_dataset = ecthr_dataset.remove_columns(\"facts\")"
   ],
   "id": "cc2df7d0da5e4328",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0bef358b6214b7b830409e833ea8a9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:24.248022Z",
     "start_time": "2024-05-28T18:33:24.245089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = ecthr_dataset[\"train\"]\n",
    "val = ecthr_dataset[\"validation\"]\n",
    "test = ecthr_dataset[\"test\"]"
   ],
   "id": "43a3d065e7e80583",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:24.256468Z",
     "start_time": "2024-05-28T18:33:24.248988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config =  LoraConfig(\n",
    "        r=LORA_R,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        task_type=LORA_TASK_TYPE,\n",
    "        bias=\"none\"\n",
    ")"
   ],
   "id": "79702f6a279249d1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:24.383696Z",
     "start_time": "2024-05-28T18:33:24.257448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "56fe4e927b2759d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,428,352 || all params: 1,380,690,752 || trainable%: 0.6104\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:25.178229Z",
     "start_time": "2024-05-28T18:33:24.384514Z"
    }
   },
   "cell_type": "code",
   "source": "model.to(\"cuda\")",
   "id": "bccf92a23ac3a46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MambaForSequenceClassification(\n",
       "      (embeddings): lora.Embedding(\n",
       "        (base_layer): Embedding(50280, 2048)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Identity()\n",
       "        )\n",
       "        (lora_A): ModuleDict()\n",
       "        (lora_B): ModuleDict()\n",
       "        (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 8x50280 (cuda:0)])\n",
       "        (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (cuda:0)])\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-47): 48 x MambaBlock(\n",
       "          (norm): MambaRMSNorm()\n",
       "          (mixer): MambaMixer(\n",
       "            (conv1d): Conv1d(4096, 4096, kernel_size=(4,), stride=(1,), padding=(3,), groups=4096)\n",
       "            (act): SiLU()\n",
       "            (in_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (x_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=160, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=160, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (dt_proj): Linear(in_features=128, out_features=4096, bias=True)\n",
       "            (out_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=2048, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Identity()\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): MambaRMSNorm()\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=2048, out_features=41, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:25.185653Z",
     "start_time": "2024-05-28T18:33:25.179090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ],
   "id": "cbc50cb119f59b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.embeddings.lora_embedding_A.default\n",
      "base_model.model.embeddings.lora_embedding_B.default\n",
      "base_model.model.layers.0.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.0.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.1.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.2.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.3.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.4.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.5.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.6.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.7.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.8.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.9.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.10.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.11.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.12.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.13.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.14.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.15.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.16.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.17.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.18.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.19.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.20.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.21.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.22.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.23.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.24.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.25.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.26.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.27.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.28.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.29.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.30.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.31.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.32.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.33.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.34.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.35.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.36.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.37.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.38.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.39.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.40.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.41.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.42.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.43.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.44.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.45.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.46.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.in_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.x_proj.lora_B.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_A.default.weight\n",
      "base_model.model.layers.47.mixer.out_proj.lora_B.default.weight\n",
      "base_model.model.classifier.modules_to_save.default.weight\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:25.224959Z",
     "start_time": "2024-05-28T18:33:25.186649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= OUTPUT_DIR,\n",
    "    run_name= RUN_NAME,\n",
    "    learning_rate= LEARNING_RATE,\n",
    "    lr_scheduler_type= \"constant\",\n",
    "    warmup_ratio= WARMUP_RATIO,\n",
    "    max_grad_norm= MAX_GRAD_NORM,\n",
    "    per_device_train_batch_size= BATCH_SIZE,\n",
    "    per_device_eval_batch_size= BATCH_SIZE_EVAL,\n",
    "    gradient_accumulation_steps= GRADIENT_ACCUMULATION_STEPS,#\n",
    "    group_by_length= USE_LENGTH_GROUPING,\n",
    "    num_train_epochs= EPOCHS,\n",
    "    weight_decay= WEIGHT_DECAY,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps= EVAL_STEPS,\n",
    "    eval_accumulation_steps = EVAL_ACCUMULATION_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps= EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to= REPORT_TO,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps= LOGGING_STEPS,\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ],
   "id": "4aea53a3acaa584f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T18:33:25.395776Z",
     "start_time": "2024-05-28T18:33:25.225931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = SimpleBCELossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "33280cfe33e287e1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:19:55.649309Z",
     "start_time": "2024-05-28T18:33:25.396697Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "db97522ffc2fbbd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33melisabeth-fittschen\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/efi/Desktop/MasterArbeit/_0_mamba_vs_neo/src/mamba/wandb/run-20240528_203332-cvsczb02</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/cvsczb02' target=\"_blank\">mamba_run_512_tokens_6_epochs_no_silver_3000</a></strong> to <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/cvsczb02' target=\"_blank\">https://wandb.ai/elisabeth-fittschen/mamba_vs_neo_ecthr/runs/cvsczb02</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3372' max='3372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3372/3372 18:45:47, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Strict Accuracy</th>\n",
       "      <th>Hamming Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.133901</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.955707</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>0.287843</td>\n",
       "      <td>0.016072</td>\n",
       "      <td>0.407778</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>0.222424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.111182</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.956488</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>0.421911</td>\n",
       "      <td>0.022534</td>\n",
       "      <td>0.219394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.092130</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.062729</td>\n",
       "      <td>0.480250</td>\n",
       "      <td>0.070699</td>\n",
       "      <td>0.676957</td>\n",
       "      <td>0.057952</td>\n",
       "      <td>0.372121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.079394</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.973707</td>\n",
       "      <td>0.105332</td>\n",
       "      <td>0.596557</td>\n",
       "      <td>0.145408</td>\n",
       "      <td>0.779843</td>\n",
       "      <td>0.092426</td>\n",
       "      <td>0.483030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.074962</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.974585</td>\n",
       "      <td>0.118088</td>\n",
       "      <td>0.619430</td>\n",
       "      <td>0.146742</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.103858</td>\n",
       "      <td>0.513939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.071357</td>\n",
       "      <td>0.367000</td>\n",
       "      <td>0.975902</td>\n",
       "      <td>0.128210</td>\n",
       "      <td>0.652846</td>\n",
       "      <td>0.147503</td>\n",
       "      <td>0.776756</td>\n",
       "      <td>0.117650</td>\n",
       "      <td>0.563030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.068726</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.977293</td>\n",
       "      <td>0.151018</td>\n",
       "      <td>0.674817</td>\n",
       "      <td>0.201982</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>0.133127</td>\n",
       "      <td>0.585455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.065422</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.978171</td>\n",
       "      <td>0.142159</td>\n",
       "      <td>0.684970</td>\n",
       "      <td>0.192643</td>\n",
       "      <td>0.816961</td>\n",
       "      <td>0.128454</td>\n",
       "      <td>0.589697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.064426</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.978756</td>\n",
       "      <td>0.169446</td>\n",
       "      <td>0.691244</td>\n",
       "      <td>0.206828</td>\n",
       "      <td>0.832622</td>\n",
       "      <td>0.150514</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.063103</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.979634</td>\n",
       "      <td>0.177104</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.210953</td>\n",
       "      <td>0.834290</td>\n",
       "      <td>0.160042</td>\n",
       "      <td>0.616364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.979415</td>\n",
       "      <td>0.191741</td>\n",
       "      <td>0.708966</td>\n",
       "      <td>0.224229</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.174909</td>\n",
       "      <td>0.623030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.062587</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.979268</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.708904</td>\n",
       "      <td>0.229774</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.164559</td>\n",
       "      <td>0.627273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.061348</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.980220</td>\n",
       "      <td>0.194313</td>\n",
       "      <td>0.718109</td>\n",
       "      <td>0.234408</td>\n",
       "      <td>0.841891</td>\n",
       "      <td>0.175129</td>\n",
       "      <td>0.626061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.060540</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.196789</td>\n",
       "      <td>0.714485</td>\n",
       "      <td>0.227259</td>\n",
       "      <td>0.839607</td>\n",
       "      <td>0.179446</td>\n",
       "      <td>0.621818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>0.980537</td>\n",
       "      <td>0.194752</td>\n",
       "      <td>0.724828</td>\n",
       "      <td>0.237821</td>\n",
       "      <td>0.840800</td>\n",
       "      <td>0.175448</td>\n",
       "      <td>0.636970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.060370</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.979951</td>\n",
       "      <td>0.198915</td>\n",
       "      <td>0.717137</td>\n",
       "      <td>0.228513</td>\n",
       "      <td>0.829618</td>\n",
       "      <td>0.180993</td>\n",
       "      <td>0.631515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/efi/Desktop/MasterArbeit/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3372, training_loss=0.07888669800786643, metrics={'train_runtime': 67583.9234, 'train_samples_per_second': 0.799, 'train_steps_per_second': 0.05, 'total_flos': 6.229271310431731e+17, 'train_loss': 0.07888669800786643, 'epoch': 5.994666666666666})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:19:55.652649Z",
     "start_time": "2024-05-29T13:19:55.650039Z"
    }
   },
   "cell_type": "code",
   "source": "print(trainer)",
   "id": "b24da0c5397d09c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SimpleBCELossTrainer object at 0x7fc2e5d49ae0>\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:28:04.000261Z",
     "start_time": "2024-05-29T13:19:55.653324Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(test)",
   "id": "5b4c111841d19ceb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.061180777847766876,\n",
       " 'eval_strict_accuracy': 0.499,\n",
       " 'eval_hamming_accuracy': 0.9808536585365853,\n",
       " 'eval_f1_macro': 0.175226564708734,\n",
       " 'eval_f1_micro': 0.7347076715106455,\n",
       " 'eval_precision_macro': 0.2271931387119774,\n",
       " 'eval_precision_micro': 0.8572555205047319,\n",
       " 'eval_recall_macro': 0.156072879308217,\n",
       " 'eval_recall_micro': 0.6428149024246008,\n",
       " 'eval_runtime': 488.3146,\n",
       " 'eval_samples_per_second': 2.048,\n",
       " 'eval_steps_per_second': 1.024,\n",
       " 'epoch': 5.994666666666666}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:36:12.157429Z",
     "start_time": "2024-05-29T13:28:04.001477Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = trainer.predict(test)",
   "id": "4d6cbf2282b280af",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:36:12.162855Z",
     "start_time": "2024-05-29T13:36:12.158499Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "8ee9ece7f37c6ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ -5.309937 ,  -4.5318904,  -7.400669 , ...,  -9.525612 ,\n",
       "         -9.525612 ,  -9.525612 ],\n",
       "       [ -5.094165 ,  -4.204568 ,  -6.429409 , ...,  -9.783821 ,\n",
       "         -9.783821 ,  -9.783821 ],\n",
       "       [ -6.3716455,  -5.4453177,  -7.776255 , ..., -10.779707 ,\n",
       "        -10.779707 , -10.779707 ],\n",
       "       ...,\n",
       "       [ -4.6644335,  -1.2084378,  -6.5028176, ...,  -9.241397 ,\n",
       "         -9.241397 ,  -9.241397 ],\n",
       "       [ -4.575066 ,   2.7364695,  -7.192851 , ...,  -9.672376 ,\n",
       "         -9.672376 ,  -9.672376 ],\n",
       "       [ -5.4789486,   2.2882545,  -6.3264813, ...,  -9.233077 ,\n",
       "         -9.233077 ,  -9.233077 ]], dtype=float32), label_ids=array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]]), metrics={'test_loss': 0.061180777847766876, 'test_strict_accuracy': 0.499, 'test_hamming_accuracy': 0.9808536585365853, 'test_f1_macro': 0.175226564708734, 'test_f1_micro': 0.7347076715106455, 'test_precision_macro': 0.2271931387119774, 'test_precision_micro': 0.8572555205047319, 'test_recall_macro': 0.156072879308217, 'test_recall_micro': 0.6428149024246008, 'test_runtime': 488.1512, 'test_samples_per_second': 2.049, 'test_steps_per_second': 1.024})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:36:12.206453Z",
     "start_time": "2024-05-29T13:36:12.163572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calulate_metrics_index(predictions, index):\n",
    "    logits = predictions.predictions\n",
    "    labels = predictions.label_ids\n",
    "    \n",
    "    logits = logits[:, index]\n",
    "    labels = labels[:, index]\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    count_correct = np.sum(labels)\n",
    "    count_predicted = np.sum(predictions)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'count_cases': count_correct,\n",
    "        'count_predicted': count_predicted\n",
    "    }\n"
   ],
   "id": "555e12e100ce0f50",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:36:12.275385Z",
     "start_time": "2024-05-29T13:36:12.207407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = utils_ecthr.ARTICLES_ID\n",
    "ids = {v: k for k, v in ids.items()}\n",
    "desc = utils_ecthr.ARTICLES_DESC\n"
   ],
   "id": "9e98169c432a3e5",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:36:12.397862Z",
     "start_time": "2024-05-29T13:36:12.276434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(0, 41):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Label {i}\")\n",
    "    print(ids[i])\n",
    "    print(desc[ids[i]])\n",
    "    print(calulate_metrics_index(predictions, i))"
   ],
   "id": "21914b194e6829cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Label 0\n",
      "2\n",
      "Right to life\n",
      "{'f1': 0.8467153284671532, 'precision': 0.9508196721311475, 'recall': 0.7631578947368421, 'count_cases': 76, 'count_predicted': 61}\n",
      "--------------------------------------------------\n",
      "Label 1\n",
      "3\n",
      "Prohibition of torture\n",
      "{'f1': 0.8620689655172413, 'precision': 0.8695652173913043, 'recall': 0.8547008547008547, 'count_cases': 234, 'count_predicted': 230}\n",
      "--------------------------------------------------\n",
      "Label 2\n",
      "4\n",
      "Prohibition of slavery and forced labour\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 3\n",
      "5\n",
      "Right to liberty and security\n",
      "{'f1': 0.8148148148148148, 'precision': 0.9225806451612903, 'recall': 0.7295918367346939, 'count_cases': 196, 'count_predicted': 155}\n",
      "--------------------------------------------------\n",
      "Label 4\n",
      "6\n",
      "Right to a fair trial\n",
      "{'f1': 0.8071519795657727, 'precision': 0.8123393316195373, 'recall': 0.8020304568527918, 'count_cases': 394, 'count_predicted': 389}\n",
      "--------------------------------------------------\n",
      "Label 5\n",
      "7\n",
      "No punishment without law\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 10, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 6\n",
      "8\n",
      "Right to respect for private and family life\n",
      "{'f1': 0.7648902821316614, 'precision': 0.9312977099236641, 'recall': 0.648936170212766, 'count_cases': 188, 'count_predicted': 131}\n",
      "--------------------------------------------------\n",
      "Label 7\n",
      "9\n",
      "Freedom of thought, conscience and religion\n",
      "{'f1': 0.42857142857142855, 'precision': 1.0, 'recall': 0.2727272727272727, 'count_cases': 11, 'count_predicted': 3}\n",
      "--------------------------------------------------\n",
      "Label 8\n",
      "10\n",
      "Freedom of expression\n",
      "{'f1': 0.8042328042328042, 'precision': 0.9156626506024096, 'recall': 0.7169811320754716, 'count_cases': 106, 'count_predicted': 83}\n",
      "--------------------------------------------------\n",
      "Label 9\n",
      "11\n",
      "Freedom of assembly and association\n",
      "{'f1': 0.5569620253164557, 'precision': 0.6111111111111112, 'recall': 0.5116279069767442, 'count_cases': 43, 'count_predicted': 36}\n",
      "--------------------------------------------------\n",
      "Label 10\n",
      "12\n",
      "Right to marry\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 4, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 11\n",
      "13\n",
      "Right to an effective remedy\n",
      "{'f1': 0.22535211267605634, 'precision': 0.8421052631578947, 'recall': 0.13008130081300814, 'count_cases': 123, 'count_predicted': 19}\n",
      "--------------------------------------------------\n",
      "Label 12\n",
      "14\n",
      "Prohibition of discrimination\n",
      "{'f1': 0.25, 'precision': 0.625, 'recall': 0.15625, 'count_cases': 32, 'count_predicted': 8}\n",
      "--------------------------------------------------\n",
      "Label 13\n",
      "15\n",
      "Derogation in time of emergency\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 3, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 14\n",
      "16\n",
      "Restrictions on political activity of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 15\n",
      "17\n",
      "Prohibition of abuse of rights\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 16\n",
      "18\n",
      "Limitation on use of restrictions on rights\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 14, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 17\n",
      "34\n",
      "Individual applications\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 48, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 18\n",
      "38\n",
      "Examination of the case\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 19\n",
      "39\n",
      "Friendly settlements\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 20\n",
      "46\n",
      "Binding force and execution of judgments\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 21, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 21\n",
      "P1-1\n",
      "Protection of property\n",
      "{'f1': 0.8235294117647058, 'precision': 0.8344370860927153, 'recall': 0.8129032258064516, 'count_cases': 155, 'count_predicted': 151}\n",
      "--------------------------------------------------\n",
      "Label 22\n",
      "P1-2\n",
      "Right to education\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 5, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 23\n",
      "P1-3\n",
      "Right to free elections\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 2}\n",
      "--------------------------------------------------\n",
      "Label 24\n",
      "P3-1\n",
      "Right to free elections\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 25\n",
      "P4-1\n",
      "Prohibition of imprisonment for debt\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 26\n",
      "P4-2\n",
      "Freedom of movement\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 6, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 27\n",
      "P4-3\n",
      "Prohibition of expulsion of nationals\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 28\n",
      "P4-4\n",
      "Prohibition of collective expulsion of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 29\n",
      "P6-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 30\n",
      "P6-2\n",
      "Death penalty in time of war\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 31\n",
      "P6-3\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 32\n",
      "P7-1\n",
      "Procedural safeguards relating to expulsion of aliens\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 33\n",
      "P7-2\n",
      "Right of appeal in criminal matters\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 4, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 34\n",
      "P7-3\n",
      "Compensation for wrongful conviction\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 2, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 35\n",
      "P7-4\n",
      "Right not to be tried or punished twice\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 5, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 36\n",
      "P7-5\n",
      "Equality between spouses\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 1, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 37\n",
      "P12-1\n",
      "General prohibition of discrimination\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 38\n",
      "P13-1\n",
      "Abolition of the death penalty\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 39\n",
      "P13-2\n",
      "Prohibition of derogations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n",
      "--------------------------------------------------\n",
      "Label 40\n",
      "P13-3\n",
      "Prohibition of reservations\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'count_cases': 0, 'count_predicted': 0}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:36:12.403239Z",
     "start_time": "2024-05-29T13:36:12.398698Z"
    }
   },
   "cell_type": "code",
   "source": "calulate_metrics_index(predictions, 2)",
   "id": "98b38f03c11137fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'count_cases': 3,\n",
       " 'count_predicted': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
