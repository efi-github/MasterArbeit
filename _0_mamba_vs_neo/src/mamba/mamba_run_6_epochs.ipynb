{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.176419Z",
     "start_time": "2024-05-27T05:22:52.169526Z"
    }
   },
   "source": [
    "from _0_mamba_vs_neo.models.MambaForSequenceClassification import MambaForSequenceClassification\n",
    "import _0_mamba_vs_neo.datasets.ecthr.utils_ecthr as utils_ecthr"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.672664Z",
     "start_time": "2024-05-27T05:22:54.177424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, hamming_loss\n",
    "import os"
   ],
   "id": "9fb2a38aeb33a5e2",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.677459Z",
     "start_time": "2024-05-27T05:22:54.673422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "\n",
    "For speed we will use only sequences up to 512 tokens, but train for 6 epochs.\n",
    "\"\"\""
   ],
   "id": "ac5ed7f616dc4907",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.684950Z",
     "start_time": "2024-05-27T05:22:54.678887Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"WANDB_PROJECT\"] = \"mamba_vs_neo_ecthr\"",
   "id": "e432f5a75cfa04ed",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.692691Z",
     "start_time": "2024-05-27T05:22:54.685794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CONFIGS:\n",
    "\"\"\""
   ],
   "id": "7302d5b13c10aea0",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.699655Z",
     "start_time": "2024-05-27T05:22:54.693372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    general:\n",
    "        - RUN_NAME: str\n",
    "            name of the run\n",
    "        - OUTPUT_DIR: str\n",
    "            directory to save the model and logs\n",
    "        - SEED: int\n",
    "            random seed to use\n",
    "        - REPORT_TO: str\n",
    "\"\"\"\n",
    "RUN_NAME = \"mamba_run_512_tokens_6_epochs\"\n",
    "OUTPUT_DIR = f\"_0_mamba_vs_neo/models/mamba/{RUN_NAME}\"\n",
    "SEED = 42\n",
    "REPORT_TO = \"wandb\""
   ],
   "id": "89a6f0a4fc3c0f0d",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.708346Z",
     "start_time": "2024-05-27T05:22:54.700540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    dataset:\n",
    "        - ALLEGATIONS: bool\n",
    "            True: use allegation data for the cases, so what laws did the cases allegedly violate\n",
    "            False: use court decisions, so what laws did the court decide the cases violated\n",
    "        - SILVER: bool\n",
    "            True: only use facts which were deemed relevant by the court\n",
    "            False: use all facts\n",
    "        - MULTI_LABEL: bool\n",
    "            True: use multi-label classification (which law was (allegedly) violated)\n",
    "            False: use binary classification (was there a law (allegedly) violated)\n",
    "        - FREQUENCY_THRESHOLD: int\n",
    "            minimum number of cases a law must be (allegedly) violated in to be considered\n",
    "        - NUM_LABELS: int\n",
    "            number of labels in the dataset (ecthr: 41)\n",
    "        - MAX_LENGTH: int\n",
    "            maximum number of tokens in a sequence     \n",
    "\"\"\"\n",
    "ALLEGATIONS = True\n",
    "SILVER = True\n",
    "MULTI_LABEL = True\n",
    "FREQUENCY_THRESHOLD = 0\n",
    "NUM_LABELS = 41\n",
    "\n",
    "MAX_LENGTH = 512"
   ],
   "id": "6befe586279fd39c",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.716890Z",
     "start_time": "2024-05-27T05:22:54.709076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    training:\n",
    "        - EPOCHS: int\n",
    "            number of times to iterate over the dataset\n",
    "        - LEARNING_RATE: float\n",
    "            rate at which the model learns\n",
    "        - BATCH_SIZE: int\n",
    "            number of sequences in a batch\n",
    "        - GRADIENT_ACCUMULATION_STEPS: int\n",
    "            number of batches to accumulate gradients over\n",
    "        - USE_LENGTH_GROUPING: bool\n",
    "            True: group sequences of similar length together to minimize padding\n",
    "            False: do not group sequences by length\n",
    "        - WARMUP_RATIO: float\n",
    "            ratio of training steps to warmup steps\n",
    "        - MAX_GRAD_NORM: float\n",
    "            maximum gradient norm to clip to\n",
    "        - WEIGHT_DECAY: float\n",
    "            weight decay to apply to the model\n",
    "\"\"\"\n",
    "EPOCHS = 6\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 8\n",
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "print(\"true batch size:\", BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)\n",
    "\n",
    "WARMUP_RATIO = 0.1\n",
    "MAX_GRAD_NORM = 0.3\n",
    "WEIGHT_DECAY = 0.001\n",
    "\n",
    "USE_LENGTH_GROUPING = True"
   ],
   "id": "893de6da13f235d7",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.724166Z",
     "start_time": "2024-05-27T05:22:54.717609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    evaluation:\n",
    "        - EVAL_STEPS: int\n",
    "            number of steps between evaluations\n",
    "        - BATCH_SIZE_EVAL: int\n",
    "            number of sequences in a batch for evaluation\n",
    "        - LOGGING_STEPS: int\n",
    "            number of steps between logging\n",
    "        - EVAL_ACCUMULATION_STEPS: int\n",
    "            number eval batches to calculate before copying to the cpu, if the eval requires a lot of memory this is helpful\n",
    "\"\"\"\n",
    "EVAL_STEPS = 200\n",
    "BATCH_SIZE_EVAL = BATCH_SIZE\n",
    "LOGGING_STEPS = 100\n",
    "EVAL_ACCUMULATION_STEPS = 20"
   ],
   "id": "baba926e7f85c13b",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.732561Z",
     "start_time": "2024-05-27T05:22:54.725979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    model:\n",
    "        - MODEL_NAME: str\n",
    "            name of the model to use\n",
    "        - LORA_TASK_TYPE:\n",
    "        - LORA_R: int\n",
    "           r is the rank of the approximation\n",
    "        - LORA_TARGET_MODULES: list\n",
    "            list of modules to target with LoRA\n",
    "\"\"\"\n",
    "MODEL_NAME = \"state-spaces/mamba-1.4b-hf\"\n",
    "LORA_TASK_TYPE = TaskType.SEQ_CLS\n",
    "LORA_R = 8\n",
    "LORA_TARGET_MODULES = [\"x_proj\", \"embeddings\", \"in_proj\", \"out_proj\"]"
   ],
   "id": "a1937d47960adb9",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.740544Z",
     "start_time": "2024-05-27T05:22:54.733295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    \n",
    "    precision_macro, recall_macto, f1_macro, _ = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, predictions, average='micro', zero_division=0)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'strict_accuracy': accuracy,\n",
    "        'hamming_accuracy': 1 - hamming_loss(labels, predictions),\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_macro': recall_macto,\n",
    "        'recall_micro': recall_micro\n",
    "    }"
   ],
   "id": "ca5335c6d3836d38",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:54.748045Z",
     "start_time": "2024-05-27T05:22:54.741271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleBCELossTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = self.loss_fct(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "id": "a5429b5b3fa7540c",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:56.518787Z",
     "start_time": "2024-05-27T05:22:54.748778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MambaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\")"
   ],
   "id": "6267f525c2c7421f",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:56.521606Z",
     "start_time": "2024-05-27T05:22:56.519584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.pad_token_id = tokenizer.eos_token_id"
   ],
   "id": "58d4063fa0ee2176",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:56.529090Z",
     "start_time": "2024-05-27T05:22:56.522356Z"
    }
   },
   "cell_type": "code",
   "source": "collator = DataCollatorWithPadding(tokenizer=tokenizer, padding = True)",
   "id": "8b1592b4547f7fc9",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:59.538910Z",
     "start_time": "2024-05-27T05:22:56.529807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ecthr_dataset = utils_ecthr.load_ecthr_dataset(allegations=ALLEGATIONS, silver=SILVER, is_multi_label=MULTI_LABEL, frequency_threshold=FREQUENCY_THRESHOLD)\n",
    "ecthr_dataset = utils_ecthr.tokenize_dataset(ecthr_dataset, tokenizer, max_length=MAX_LENGTH)\n",
    "ecthr_dataset = ecthr_dataset.remove_columns(\"facts\")"
   ],
   "id": "cc2df7d0da5e4328",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:59.541606Z",
     "start_time": "2024-05-27T05:22:59.539579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = ecthr_dataset[\"train\"]\n",
    "val = ecthr_dataset[\"validation\"]\n",
    "test = ecthr_dataset[\"test\"]"
   ],
   "id": "43a3d065e7e80583",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:59.550059Z",
     "start_time": "2024-05-27T05:22:59.542273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config =  LoraConfig(\n",
    "        r=LORA_R,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        task_type=LORA_TASK_TYPE,\n",
    "        bias=\"none\"\n",
    ")"
   ],
   "id": "79702f6a279249d1",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:22:59.679852Z",
     "start_time": "2024-05-27T05:22:59.550793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "56fe4e927b2759d8",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:23:00.486106Z",
     "start_time": "2024-05-27T05:22:59.680728Z"
    }
   },
   "cell_type": "code",
   "source": "model.to(\"cuda\")",
   "id": "bccf92a23ac3a46",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:23:00.493090Z",
     "start_time": "2024-05-27T05:23:00.486854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ],
   "id": "cbc50cb119f59b2f",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:23:00.553120Z",
     "start_time": "2024-05-27T05:23:00.493816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= OUTPUT_DIR,\n",
    "    run_name= RUN_NAME,\n",
    "    learning_rate= LEARNING_RATE,\n",
    "    lr_scheduler_type= \"constant\",\n",
    "    warmup_ratio= WARMUP_RATIO,\n",
    "    max_grad_norm= MAX_GRAD_NORM,\n",
    "    per_device_train_batch_size= BATCH_SIZE,\n",
    "    per_device_eval_batch_size= BATCH_SIZE_EVAL,\n",
    "    gradient_accumulation_steps= GRADIENT_ACCUMULATION_STEPS,#\n",
    "    group_by_length= USE_LENGTH_GROUPING,\n",
    "    num_train_epochs= EPOCHS,\n",
    "    weight_decay= WEIGHT_DECAY,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps= EVAL_STEPS,\n",
    "    eval_accumulation_steps = EVAL_ACCUMULATION_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps= EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to= REPORT_TO,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps= LOGGING_STEPS,\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ],
   "id": "4aea53a3acaa584f",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T05:23:00.712904Z",
     "start_time": "2024-05-27T05:23:00.553951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = SimpleBCELossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "33280cfe33e287e1",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:11:29.951246Z",
     "start_time": "2024-05-27T05:23:00.713705Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "db97522ffc2fbbd2",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:11:29.955186Z",
     "start_time": "2024-05-27T10:11:29.951943Z"
    }
   },
   "cell_type": "code",
   "source": "print(trainer)",
   "id": "b24da0c5397d09c3",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:13:16.174078Z",
     "start_time": "2024-05-27T10:11:29.955943Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate(test)",
   "id": "5b4c111841d19ceb",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:15:01.295909Z",
     "start_time": "2024-05-27T10:13:16.174864Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = trainer.predict(test)",
   "id": "4d6cbf2282b280af",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:15:01.301877Z",
     "start_time": "2024-05-27T10:15:01.298267Z"
    }
   },
   "cell_type": "code",
   "source": "predictions",
   "id": "8ee9ece7f37c6ba",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:15:01.312299Z",
     "start_time": "2024-05-27T10:15:01.302574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calulate_metrics_index(predictions, index):\n",
    "    logits = predictions.predictions\n",
    "    labels = predictions.label_ids\n",
    "    \n",
    "    logits = logits[:, index]\n",
    "    labels = labels[:, index]\n",
    "    \n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    predictions = (probs > 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary', zero_division=0)\n",
    "    \n",
    "    count_correct = np.sum(labels)\n",
    "    count_predicted = np.sum(predictions)\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'count_cases': count_correct,\n",
    "        'count_predicted': count_predicted\n",
    "    }\n"
   ],
   "id": "555e12e100ce0f50",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:15:01.323625Z",
     "start_time": "2024-05-27T10:15:01.313095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = utils_ecthr.ARTICLES_ID\n",
    "ids = {v: k for k, v in ids.items()}\n",
    "desc = utils_ecthr.ARTICLES_DESC\n"
   ],
   "id": "9e98169c432a3e5",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:15:01.395403Z",
     "start_time": "2024-05-27T10:15:01.324417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(0, 41):\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Label {i}\")\n",
    "    print(ids[i])\n",
    "    print(desc[ids[i]])\n",
    "    print(calulate_metrics_index(predictions, i))"
   ],
   "id": "21914b194e6829cb",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:15:01.400593Z",
     "start_time": "2024-05-27T10:15:01.396173Z"
    }
   },
   "cell_type": "code",
   "source": "calulate_metrics_index(predictions, 2)",
   "id": "98b38f03c11137fa",
   "execution_count": 32,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
